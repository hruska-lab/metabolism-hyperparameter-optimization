{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "460f62c4-647f-4d27-9ef5-52b7c011cb6e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# isozyme.csv ... three columns in this order: index of mol, smiles, half-life"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f60df3c7-6f7f-40cf-8da3-99ed173e24b1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# isozyme_split.csv ... same three colums, but mols and their indexes are shuffeled\n",
    "# after using ScaffoldSplitter from deepchem on the list of smiles or train_test_split from sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "90de08e1-e37c-401a-8203-c48e57c08311",
   "metadata": {},
   "outputs": [],
   "source": [
    "# orig 3A4 csv file from ChEMBL -> only mols w/ \"Standard Type\" == \"T1/2\" (must be uppercase*)\n",
    "# and only \"Standard Value\" column -> 3A4.csv w/ 70 mols\n",
    "# * ... mols w/ \"t1/2\" don't have a \"Standard Value\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e315a7cc-9c57-40f6-a176-45fc2c6bfdac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# orig RLM csv file from PubChem -> remove invalid smiles (how?*) -> RLM.csv w/ 2524 mols\n",
    "# * ... one way would be to convert them to jazzy molecule features\n",
    "# and remove mols with empty dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "437e96ee-c1cc-48a8-be76-c337fd2f35e0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# orig HLC csv file from PubChem -> convert \">30\" to 30 -> HLC.csv w/ 189 mols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9e1552ad-a611-413a-b0d2-ccd245e4d499",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import deepchem as dc\n",
    "from tdc.single_pred import ADME\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from jazzy.api import molecular_vector_from_smiles as mol_vect\n",
    "from project_resources.import_utils import NotebookFinder\n",
    "sys.meta_path.append(NotebookFinder())\n",
    "from project_resources.cytochrome_P450 import isz_csv_data_formatting, split_csv_data_formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d425f5e3-a2ec-47dd-a882-8bc65db5aa1e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "isozymes = [\"3A4\", \"RLM\", \"HLC\"]\n",
    "tdc_benchmarks = [\"obach\", \"microsome\", \"hepatocyte\"]\n",
    "rel_paths = {\n",
    "    \"3A4_source\": r\"project_resources/ChEMBL_3A4.csv\",\n",
    "    \"3A4_sep\": \";\",\n",
    "    \"3A4\": r\"project_resources/3A4.csv\",\n",
    "    \"3A4_train_scaff\": r\"project_resources/data_splits/scaffold_splitter/3A4_train.csv\",\n",
    "    \"3A4_test_scaff\": r\"project_resources/data_splits/scaffold_splitter/3A4_test.csv\",\n",
    "    \"3A4_train_rand\": r\"project_resources/data_splits/random/3A4_train.csv\",\n",
    "    \"3A4_test_rand\": r\"project_resources/data_splits/random/3A4_test.csv\",\n",
    "\n",
    "    \"RLM_source\": r\"project_resources/AID_1508591_datatable_all.csv\",\n",
    "    \"RLM_sep\": \",\",\n",
    "    \"RLM\": r\"project_resources/RLM.csv\",\n",
    "    \"RLM_train_scaff\": r\"project_resources/data_splits/scaffold_splitter/RLM_train.csv\",\n",
    "    \"RLM_test_scaff\": r\"project_resources/data_splits/scaffold_splitter/RLM_test.csv\",\n",
    "    \"RLM_train_rand\": r\"project_resources/data_splits/random/RLM_train.csv\",\n",
    "    \"RLM_test_rand\": r\"project_resources/data_splits/random/RLM_test.csv\",\n",
    "\n",
    "\n",
    "    \"HLC_source\": r\"project_resources/AID_1508603_datatable_all.csv\",\n",
    "    \"HLC_sep\": \",\",\n",
    "    \"HLC\": r\"project_resources/HLC.csv\",\n",
    "    \"HLC_train_scaff\": r\"project_resources/data_splits/scaffold_splitter/HLC_train.csv\",\n",
    "    \"HLC_test_scaff\": r\"project_resources/data_splits/scaffold_splitter/HLC_test.csv\",\n",
    "    \"HLC_train_rand\": r\"project_resources/data_splits/random/HLC_train.csv\",\n",
    "    \"HLC_test_rand\": r\"project_resources/data_splits/random/HLC_test.csv\"\n",
    "}\n",
    "smiles = {}\n",
    "halflives = {}\n",
    "years = {}\n",
    "smiles_as_index = {}  # structure: {isozyme: {\"smi\": (idx, halflife, published),...}}\n",
    "sorted_smiles = {}\n",
    "smi_as_idx_time_sorted = {}  # same structure as smiles_as_index but tuples in each isozyme are sorted by publication date\n",
    "years_split = {}\n",
    "rand_split_smiles = {}\n",
    "scaff_split_smiles = {}\n",
    "time_split_smiles = {}\n",
    "tdc_datasets = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6786e0a4-813a-4d3f-abe5-d8cb9bc7df60",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3A4.csv already exists in dir\n",
      "RLM.csv already exists in dir\n",
      "HLC.csv already exists in dir\n"
     ]
    }
   ],
   "source": [
    "# create and/or load csv files\n",
    "for isozyme in isozymes:\n",
    "    isz_csv_data_formatting(rel_paths[f\"{isozyme}_source\"], isozyme, sep=rel_paths[f\"{isozyme}_sep\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "45c10a3d-0ef8-4071-ae9a-656175d0c4e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['COc1ccc2[nH]cc(CCNC(C)=O)c2c1', 'C[C@@H]1CN(CC(=O)N2CC(C)(C)c3nnc(Cc4ccc(F)cc4F)cc32)[C@@H](CN2Cc3c(F)cccc3C2=O)CN1', 'O=c1[nH]c2ccccc2n1C1CCN(CCCC(c2ccc(F)cc2)c2ccc(F)cc2)CC1', 'C[C@@H]1CN(CC(=O)N2CC(C)(C)c3ncc([C@@H](O)c4ccc(F)cc4)cc32)[C@@H](CN2[C@H](C)COC[C@H]2C)CN1', 'C[C@@H]1CN(CC(=O)N2CC(C)(C)c3ncc(Cc4ccc(F)cc4)cc32)[C@@H](CN2Cc3ccccc3C2=O)CN1']\n",
      "[0.0550250664243987, 0.1940522960504559, 0.0069483598138766, 0.0772707572389795, 0.1245136673422085]\n",
      "(1, 0.0550250664243987, 2004)\n",
      "['COc1cc2c3cc1Oc1c(O)c(OC)cc4c1[C@@H](Cc1ccc(cc1)Oc1cc(ccc1O)C[C@H]3N(C)CC2)N(C)CC4', 'O=C(NCCc1ccccn1)C1CC(=O)N(c2n[nH]c3cc(Br)ccc23)C1', 'Nc1nc2c(s1)C(c1ccc(F)c(F)c1)CC(=O)N2', 'Cc1nc(-c2ccco2)cc([C@H]2CN3CC[C@H]2C[C@@H]3CNC(=O)NC2CCCCC2)n1', 'Cc1ccc(-n2c(=O)c3oc4ccccc4c3n(CC(=O)Nc3ccc(F)c(Cl)c3)c2=O)cc1C']\n",
      "[1.0, 0.9955079474775398, 0.9937802349689012, 0.9917069799585349, 0.990324809951624]\n",
      "(1, 1.0, 2005)\n",
      "['Cc1cc2cc(-c3c(C)noc3C)nc(Nc3cccc(F)c3)c2o1', 'CN(Cc1cccc(F)c1)C1CCOc2ccccc21', 'Fc1cccc(-c2cnc(Nc3cncnc3)c3c2CCO3)c1', 'O=C(c1ccc(-c2ncc3cnc(-c4cccc(F)c4)cn23)cc1)N1CCc2cccnc21', 'Cc1ccc(NC(=O)c2nc3sccn3c2-c2cccc(C#N)c2)cc1']\n",
      "[0.0053380782918149, 0.0088967971530249, 0.0177935943060498, 0.0862989323843416, 0.0871886120996441]\n",
      "(1, 0.0053380782918149, 2018)\n"
     ]
    }
   ],
   "source": [
    "# read smiles, their idxs, corresponding half-life and publication year as tuple(tuple(idx, smiles, half-life), year)\n",
    "for isozyme in isozymes:\n",
    "    df = pd.read_csv(rel_paths[isozyme])\n",
    "    index = list(df[\"mol_idx\"])\n",
    "    _smiles = list(df[\"smiles\"])\n",
    "    halflife = list(df[\"half-life\"])\n",
    "    published = list(df[\"published\"])\n",
    "    smiles[isozyme] = _smiles\n",
    "    halflives[isozyme] = halflife\n",
    "    years[isozyme] = published\n",
    "    smiles_as_index[isozyme] = {}\n",
    "    for idx, smi, val, year in zip(index, _smiles, halflife, published):\n",
    "        smiles_as_index[isozyme][smi] = (idx, val, year)\n",
    "    first_smiles = smiles[isozyme][0]\n",
    "    print(f\"{smiles[isozyme][:5]}\\n{halflives[isozyme][:5]}\\n{smiles_as_index[isozyme][first_smiles]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b9f1d452-c818-484f-aba5-d8c040394e15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['O=C(NC1CCN(CCc2c[nH]c3ccccc23)CC1)c1ccccc1', 'COc1cc(N)c(Cl)cc1C(=O)NC1CCN(Cc2ccccc2)CC1', 'O=C(CCCN1CCC(n2c(=O)[nH]c3ccccc32)CC1)c1ccc(F)cc1', 'COc1ccc(CCN2CCC(Nc3nc4ccccc4n3Cc3ccc(F)cc3)CC2)cc1', 'CC1(C)O[C@@H]2C[C@H]3[C@@H]4CCC5=CC(=O)C=C[C@]5(C)[C@@]4(F)[C@@H](O)C[C@]3(C)[C@]2(C(=O)CO)O1']\n",
      "[0.0439188969472542, 0.0133402438387857, 0.0086159528284628, 0.003613173784704, 0.0327960515399637]\n",
      "(25, 0.0439188969472542, 1980)\n",
      "['O=c1c(O)c(-c2ccc(O)cc2)oc2cc(O)cc(O)c12', 'Nc1cc2nc3ccccc3oc-2cc1=O', 'NC[C@H](O)c1ccc(O)c(O)c1', 'COc1cc2c3cc1Oc1c(O)c(OC)cc4c1[C@@H](Cc1ccc(cc1)Oc1cc(ccc1O)C[C@H]3N(C)CC2)N(C)CC4', 'CCOC(=O)N1CCN(Cc2nc3c(c(=O)n(C)c(=O)n3C)n2Cc2cccc(C)c2)CC1']\n",
      "[0.1807187284035936, 0.2671043538355218, 0.4305459571527297, 1.0, 0.138217000691085]\n",
      "(865, 0.1807187284035936, 2004)\n",
      "['O=C(Nc1cnc(-c2ccccc2)nc1)c1ccccc1', 'COC(=O)[C@@H]1Cc2ncn(C)c2CN1C(=O)c1ccc(C#N)cc1', 'Cc1ccc(-c2noc([C@@H]3Cc4nc[nH]c4CN3Cc3cccc(C#N)c3)n2)cc1', 'O=C(Nc1cnc(-c2ccccc2)nc1)c1cccc(F)c1', 'Cc1ccc(-c2noc([C@@H]3Cc4nc[nH]c4CN3Cc3ccc(C(=O)O)cc3)n2)cc1']\n",
      "[1.0, 1.0, 0.4964412811387899, 0.395017793594306, 0.842526690391459]\n",
      "(107, 1.0, 2007)\n"
     ]
    }
   ],
   "source": [
    "# create a sorted version of smiles_as_index\n",
    "for isozyme in isozymes:\n",
    "    df = pd.read_csv(rel_paths[isozyme])\n",
    "    sorted_df = df.sort_values(by=\"published\", axis=0)\n",
    "    sorted_index = list(sorted_df[\"mol_idx\"])\n",
    "    _sorted_smiles = list(sorted_df[\"smiles\"])\n",
    "    sorted_halflife = list(sorted_df[\"half-life\"])\n",
    "    sorted_published = list(sorted_df[\"published\"])\n",
    "    sorted_smiles[isozyme] = _sorted_smiles\n",
    "    smi_as_idx_time_sorted[isozyme] = {}\n",
    "    for idx, smi, val, year in zip(sorted_index, _sorted_smiles, sorted_halflife, sorted_published):\n",
    "        smi_as_idx_time_sorted[isozyme][smi] = (idx, val, year)\n",
    "    first_smiles = _sorted_smiles[0]\n",
    "    print(f\"{_sorted_smiles[:5]}\\n{sorted_halflife[:5]}\\n{smi_as_idx_time_sorted[isozyme][first_smiles]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "42b735c1-7e27-460e-b22f-ad3b58671404",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3A4\n",
      "train: 56\n",
      "test: 14\n",
      "\n",
      "RLM\n",
      "train: 1421\n",
      "test: 356\n",
      "\n",
      "HLC\n",
      "train: 151\n",
      "test: 38\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# random train-test split\n",
    "for isozyme in isozymes:\n",
    "    rand_train, rand_test = train_test_split(smiles[isozyme], test_size=0.2, random_state=42)\n",
    "    rand_split_smiles[isozyme] = {}\n",
    "    rand_split_smiles[isozyme][\"train\"] = rand_train\n",
    "    rand_split_smiles[isozyme][\"test\"] = rand_test\n",
    "    print(f\"{isozyme}\\ntrain: {len(rand_split_smiles[isozyme]['train'])}\\ntest: {len(rand_split_smiles[isozyme]['test'])}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "45c5d367-cb71-4570-8a4e-8f4db4ede287",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3A4_train.csv already exists in project_resources/base_splits/random\n",
      "3A4_test.csv already exists in project_resources/base_splits/random\n",
      "RLM_train.csv already exists in project_resources/base_splits/random\n",
      "RLM_test.csv already exists in project_resources/base_splits/random\n",
      "HLC_train.csv already exists in project_resources/base_splits/random\n",
      "HLC_test.csv already exists in project_resources/base_splits/random\n"
     ]
    }
   ],
   "source": [
    "# save the random splits to csv files\n",
    "for isozyme in isozymes:\n",
    "    split_csv_data_formatting(isozyme, smiles_as_index, rand_split_smiles[isozyme], \"random\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dec6f81f-4eaa-4f93-b657-4d855b5dd41d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3A4\n",
      "train: 56\n",
      "test: 14\n",
      "\n",
      "[9, 8, 7, 5, 3, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "70\n",
      "RLM\n",
      "train: 1421\n",
      "test: 356\n",
      "\n",
      "[39, 31, 30, 22, 18, 15, 15, 15, 15, 12, 11, 10, 10, 10, 9, 8, 8, 8, 8, 7, 7, 7, 6, 6, 6, 6, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "1777\n",
      "HLC\n",
      "train: 151\n",
      "test: 38\n",
      "\n",
      "[10, 8, 4, 4, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1]\n",
      "189\n"
     ]
    }
   ],
   "source": [
    "# train-test split with deepchem's ScaffoldSplitter\n",
    "for isozyme in isozymes:\n",
    "    # create scaffolds\n",
    "    identifiers = smiles[isozyme]\n",
    "    Xs = np.zeros(len(identifiers))\n",
    "    dataset = dc.data.DiskDataset.from_numpy(X=Xs, ids=identifiers)\n",
    "    scaffoldsplitter = dc.splits.ScaffoldSplitter()\n",
    "    train, test = scaffoldsplitter.train_test_split(dataset)\n",
    "    scaffold = scaffoldsplitter.generate_scaffolds(dataset)\n",
    "    scaff_split_smiles[isozyme] = {}\n",
    "    scaff_split_smiles[isozyme][\"train\"] = train.ids.tolist()\n",
    "    scaff_split_smiles[isozyme][\"test\"] = test.ids.tolist()\n",
    "    print(f\"{isozyme}\\ntrain: {len(scaff_split_smiles[isozyme]['train'])}\\ntest: {len(scaff_split_smiles[isozyme]['test'])}\\n\")\n",
    "\n",
    "    # check the number of mols in each scaffold\n",
    "    lens = []\n",
    "    for part in scaffold:\n",
    "        lens.append(len(part))\n",
    "    print(lens)\n",
    "    total = 0\n",
    "    for _len in lens:\n",
    "        total += _len\n",
    "    print(total)\n",
    "#print(scaffold)  # use this to check the strucutre of molecules in large groups (the numbers are mol_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f5b78ef5-7dc0-4837-832a-abc3699439a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3A4_train.csv already exists in project_resources/base_splits/scaffold_splitter\n",
      "3A4_test.csv already exists in project_resources/base_splits/scaffold_splitter\n",
      "RLM_train.csv already exists in project_resources/base_splits/scaffold_splitter\n",
      "RLM_test.csv already exists in project_resources/base_splits/scaffold_splitter\n",
      "HLC_train.csv already exists in project_resources/base_splits/scaffold_splitter\n",
      "HLC_test.csv already exists in project_resources/base_splits/scaffold_splitter\n"
     ]
    }
   ],
   "source": [
    "# save the ScaffoldSplitter splits to csv files\n",
    "for isozyme in isozymes:\n",
    "    split_csv_data_formatting(isozyme, smiles_as_index, scaff_split_smiles[isozyme], \"scaffold_splitter\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "802f64d9-5e55-42c1-98b7-7a23bad91348",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3A4\n",
      "train: 56\n",
      "test: 14\n",
      "\n",
      "RLM\n",
      "train: 1421\n",
      "test: 356\n",
      "\n",
      "HLC\n",
      "train: 151\n",
      "test: 38\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# time split: train dataset ... oldest 80 % of molecules; test dataset ... newest 20 %\n",
    "for isozyme in isozymes:\n",
    "    num_mols = len(sorted_smiles[isozyme])\n",
    "    train_size = int(np.floor(num_mols * 0.8))\n",
    "    train_smiles = sorted_smiles[isozyme][:train_size]\n",
    "    test_smiles = sorted_smiles[isozyme][train_size:]\n",
    "    time_split_smiles[isozyme] = {}\n",
    "    time_split_smiles[isozyme][\"train\"] = train_smiles\n",
    "    time_split_smiles[isozyme][\"test\"] = test_smiles\n",
    "    years_split[isozyme] = {}\n",
    "    for split in [\"train\", \"test\"]:\n",
    "        years_split[isozyme][split] = []\n",
    "        for smi in time_split_smiles[isozyme][split]:\n",
    "            year = smi_as_idx_time_sorted[isozyme][smi][2]\n",
    "            years_split[isozyme][split].append(year)\n",
    "    print(f\"{isozyme}\\ntrain: {len(train_smiles)}\\ntest: {len(test_smiles)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3056aa20-d334-4d36-ab73-9157320d5255",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3A4_train.csv already exists in project_resources/base_splits/time_split\n",
      "3A4_test.csv already exists in project_resources/base_splits/time_split\n",
      "RLM_train.csv already exists in project_resources/base_splits/time_split\n",
      "RLM_test.csv already exists in project_resources/base_splits/time_split\n",
      "HLC_train.csv already exists in project_resources/base_splits/time_split\n",
      "HLC_test.csv already exists in project_resources/base_splits/time_split\n"
     ]
    }
   ],
   "source": [
    "# save the time splits to csv files\n",
    "for isozyme in isozymes:\n",
    "    split_csv_data_formatting(isozyme, smi_as_idx_time_sorted, time_split_smiles[isozyme],\n",
    "                              \"time_split\", include_year=True, years=years_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "94480987-4d95-4c30-8874-689c378dfe02",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found local copy...\n",
      "Loading...\n",
      "Done!\n",
      "Found local copy...\n",
      "Loading...\n",
      "Done!\n",
      "Found local copy...\n",
      "Loading...\n",
      "Done!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(534,) (534,) (133,) (133,)\n",
      "both obach_train.csv and obach_test.csv already exist in project_resources/jazzy_splits/TDC\n",
      "(882,) (882,) (220,) (220,)\n",
      "both microsome_train.csv and microsome_test.csv already exist in project_resources/jazzy_splits/TDC\n",
      "(970,) (970,) (243,) (243,)\n",
      "both hepatocyte_train.csv and hepatocyte_test.csv already exist in project_resources/jazzy_splits/TDC\n"
     ]
    }
   ],
   "source": [
    "# download/load benchmark datasets from TDC-ADME and their Jazzy features\n",
    "obach = ADME(name='Half_Life_Obach')\n",
    "obach_split = obach.get_split()\n",
    "tdc_datasets[\"obach\"] = obach_split\n",
    "microsome = ADME(name='Clearance_Microsome_AZ')\n",
    "microsome_split = microsome.get_split()\n",
    "tdc_datasets[\"microsome\"] = microsome_split\n",
    "hepatocyte = ADME(name='Clearance_Hepatocyte_AZ')\n",
    "hepatocyte_split = hepatocyte.get_split()\n",
    "tdc_datasets[\"hepatocyte\"] = hepatocyte_split\n",
    "\n",
    "for benchmark in tdc_benchmarks:\n",
    "    #get the smiles and half-lives from datasets\n",
    "    train_smiles = np.array(list(tdc_datasets[benchmark][\"train\"][\"Drug\"]) + list(tdc_datasets[benchmark][\"valid\"][\"Drug\"]))\n",
    "    train_halflives = np.array(list(tdc_datasets[benchmark][\"train\"][\"Y\"]) + list(tdc_datasets[benchmark][\"valid\"][\"Y\"]))\n",
    "    test_smiles = np.array(list(tdc_datasets[benchmark][\"test\"][\"Drug\"]))\n",
    "    test_halflives = np.array(list(tdc_datasets[benchmark][\"test\"][\"Y\"]))\n",
    "\n",
    "    # scale train half-lives\n",
    "    reshaped_train_halflife = np.array(train_halflives).reshape(-1, 1)\n",
    "    scaler = MinMaxScaler().fit(reshaped_train_halflife)\n",
    "    train_halflife_scaled = scaler.transform(reshaped_train_halflife)\n",
    "    train_halflives_scaled = np.array([val[0] for val in train_halflife_scaled])\n",
    "\n",
    "    # scale test half-lives\n",
    "    reshaped_test_halflife = np.array(test_halflives).reshape(-1, 1)\n",
    "    scaler = MinMaxScaler().fit(reshaped_test_halflife)\n",
    "    test_halflife_scaled = scaler.transform(reshaped_test_halflife)\n",
    "    test_halflives_scaled = np.array([val[0] for val in test_halflife_scaled])\n",
    "    \n",
    "    print(train_smiles.shape, train_halflives_scaled.shape, test_smiles.shape, test_halflives_scaled.shape)\n",
    "\n",
    "    \n",
    "    try:\n",
    "        df = pd.read_csv(f\"project_resources/jazzy_splits/TDC/{benchmark}_train.csv\")\n",
    "        df = pd.read_csv(f\"project_resources/jazzy_splits/TDC/{benchmark}_test.csv\")\n",
    "        print(f\"both {benchmark}_train.csv and {benchmark}_test.csv already exist in project_resources/jazzy_splits/TDC\")\n",
    "    \n",
    "    except FileNotFoundError:\n",
    "        # generate Jazzy features and save to csv files\n",
    "        train_jazzy_fps = []\n",
    "        train_jazzy_thalfs = []\n",
    "        test_jazzy_fps = []\n",
    "        test_jazzy_thalfs = []\n",
    "\n",
    "        for smi, thalf in zip(train_smiles, train_halflives_scaled):\n",
    "            try:\n",
    "                jazzy_fp = mol_vect(smi)\n",
    "            except:\n",
    "                jazzy_fp = None\n",
    "            if jazzy_fp and not np.isnan(np.array(list(jazzy_fp.values()))).any():\n",
    "                jazzy_fp_list = np.array([fp for fp in jazzy_fp.values()])\n",
    "                train_jazzy_fps.append(jazzy_fp_list)\n",
    "                train_jazzy_thalfs.append(thalf)\n",
    "\n",
    "        for smi, thalf in zip(test_smiles, test_halflives_scaled):\n",
    "            try:\n",
    "                jazzy_fp = mol_vect(smi)\n",
    "            except:\n",
    "                jazzy_fp = None\n",
    "            if jazzy_fp and not np.isnan(np.array(list(jazzy_fp.values()))).any():\n",
    "                jazzy_fp_list = np.array([fp for fp in jazzy_fp.values()])\n",
    "                test_jazzy_fps.append(jazzy_fp_list)\n",
    "                test_jazzy_thalfs.append(thalf)\n",
    "\n",
    "        print(np.array(train_jazzy_fps).shape, np.array(train_jazzy_thalfs).shape, np.array(test_jazzy_fps).shape, np.array(test_jazzy_thalfs).shape)\n",
    "\n",
    "        train_jazzy_csv = f\"project_resources/jazzy_splits/TDC/{benchmark}_train.csv\"\n",
    "        df = pd.DataFrame(train_jazzy_fps, columns=['sdc', 'sdx', 'sa', 'dga', 'dgp', 'dgtot'])\n",
    "        df.insert(0, \"half-life\", train_jazzy_thalfs)\n",
    "        df.to_csv(train_jazzy_csv, index=False)\n",
    "        print(f\"{train_jazzy_csv} was successfully created\")\n",
    "\n",
    "        test_jazzy_csv = f\"project_resources/jazzy_splits/TDC/{benchmark}_test.csv\"\n",
    "        df = pd.DataFrame(test_jazzy_fps, columns=['sdc', 'sdx', 'sa', 'dga', 'dgp', 'dgtot'])\n",
    "        df.insert(0, \"half-life\", test_jazzy_thalfs)\n",
    "        df.to_csv(test_jazzy_csv, index=False)\n",
    "        print(f\"{test_jazzy_csv} was successfully created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b246649b-55e6-4699-8b22-be1d5052df30",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
