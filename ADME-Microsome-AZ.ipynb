{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "242a09de-23f5-4730-8da4-b5a8af954cf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lukas\\anaconda3\\envs\\soc\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from C:\\Users\\Lukas\\Documents\\datacytochromy\\project_resources\\cytochrome_P450.ipynb\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'chembl_webresource_client'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 20\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MinMaxScaler\n\u001b[0;32m     19\u001b[0m sys\u001b[38;5;241m.\u001b[39mmeta_path\u001b[38;5;241m.\u001b[39mappend(NotebookFinder())\n\u001b[1;32m---> 20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mproject_resources\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcytochrome_P450\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m fp_from_smiles, HyperparamTuner, tanimoto, create_interactive_scatter_plot\n",
      "File \u001b[1;32m~\\Documents\\datacytochromy\\project_resources\\import_utils.py:48\u001b[0m, in \u001b[0;36mNotebookLoader.load_module\u001b[1;34m(self, fullname)\u001b[0m\n\u001b[0;32m     46\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m cell\u001b[38;5;241m.\u001b[39mcell_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcode\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m     47\u001b[0m             code \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshell\u001b[38;5;241m.\u001b[39minput_transformer_manager\u001b[38;5;241m.\u001b[39mtransform_cell(cell\u001b[38;5;241m.\u001b[39msource)\n\u001b[1;32m---> 48\u001b[0m             exec(code, mod\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m)\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshell\u001b[38;5;241m.\u001b[39muser_ns \u001b[38;5;241m=\u001b[39m save_user_ns\n",
      "File \u001b[1;32m<string>:6\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'chembl_webresource_client'"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "import joblib\n",
    "import numpy as np\n",
    "import sys\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from optuna.storages import JournalStorage, JournalFileStorage\n",
    "from tdc.single_pred import ADME\n",
    "from scipy.stats import spearmanr\n",
    "from sklearn.metrics import r2_score\n",
    "from jazzy.api import molecular_vector_from_smiles as mol_vect\n",
    "import matplotlib.pyplot as plt\n",
    "from project_resources.import_utils import NotebookFinder\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "sys.meta_path.append(NotebookFinder())\n",
    "from project_resources.cytochrome_P450 import fp_from_smiles, HyperparamTuner, tanimoto, create_interactive_scatter_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8acd3cb9-f603-4a24-9090-d651a9d7a281",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_identifiers = [\"linear\", \"KRR\", \"GB\", \"RF\", \"ANN\"]\n",
    "splitters = [\"rand\", \"scaff\", \"time\"]\n",
    "data_splits = [\"train\", \"test\"]\n",
    "feature_types = [\"morgan\", \"jazzy\"]\n",
    "\n",
    "# sampler - a method used to generate new sets of hyperparameters in each iteration of the optimization process\n",
    "samplers = {\n",
    "    'RandomSampler': optuna.samplers.RandomSampler,          # Sampler that selects hyperparameters randomly from the search space.\n",
    "    'GridSampler': optuna.samplers.GridSampler,              # Sampler that performs a grid search over the hyperparameter space.\n",
    "    'TPESampler': optuna.samplers.TPESampler,                # Sampler that uses a tree-structured Parzen estimator to model the objective function and sample new points from the search space.\n",
    "    'CmaEsSampler': optuna.samplers.CmaEsSampler,            # Sampler that uses the Covariance Matrix Adaptation Evolution Strategy algorithm to efficiently search the hyperparameter space.\n",
    "    'NSGAIISampler': optuna.samplers.NSGAIISampler,          # Multi-objective evolutionary algorithm that generates new samples using non-dominated sorting and crowding distance selection.\n",
    "    'QMCSampler': optuna.samplers.QMCSampler,                # Quasi-Monte Carlo sampler that uses low-discrepancy sequences to sample the search space in a more efficient and evenly distributed way than random sampling.\n",
    "    'BoTorchSampler': optuna.integration.BoTorchSampler,     # Sampler that leverages the BoTorch library for Bayesian optimization and can handle both continuous and categorical hyperparameters.\n",
    "    'BruteForceSampler': optuna.samplers.BruteForceSampler,  # Sampler that exhaustively evaluates all possible combinations of hyperparameters in the search space.\n",
    "}\n",
    "# pruner - a technique used to eliminate unpromising trials during the course of hyperparameter optimization.\n",
    "pruners = {\n",
    "    'BasePruner': optuna.pruners.BasePruner,                            # This is the base class for all pruning strategies in Optuna. It provides a skeleton for implementing custom pruning strategies.\n",
    "    'MedianPruner': optuna.pruners.MedianPruner,                        # A pruner that prunes unpromising trials that have median objective values, as determined in previous steps.\n",
    "    'SuccessiveHalvingPruner': optuna.pruners.SuccessiveHalvingPruner,  # This pruner repeatedly splits trials into halves, discarding the lower performing half at each iteration.\n",
    "    'HyperbandPruner': optuna.pruners.HyperbandPruner,                  # This pruner implements the Hyperband algorithm, which selects promising trials and runs them with different resource allocation schemes to determine the best one.\n",
    "    'PercentilePruner': optuna.pruners.PercentilePruner,                # A pruner that prunes unpromising trials based on their percentile rank relative to all completed trials.\n",
    "    'NopPruner': optuna.pruners.NopPruner,                              # A pruner that does nothing and does not prune any trials.\n",
    "    'ThresholdPruner': optuna.pruners.ThresholdPruner,                  # This pruner prunes trials that have not reached a certain level of performance (i.e., objective value).\n",
    "    'PatientPruner': optuna.pruners.PatientPruner,                      # This pruner prunes trials that do not show improvement over a certain number of steps (or epochs).\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b118b575-3254-4ce8-ab6a-f17421b70c30",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found local copy...\n",
      "Loading...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "data = ADME(name='Clearance_Microsome_AZ')\n",
    "split = data.get_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e9af8f83-4722-4ec0-bcfa-4f225f18c5e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(970,) (970,) (486,) (486,)\n"
     ]
    }
   ],
   "source": [
    "train_smiles = np.array(list(split[\"train\"][\"Drug\"]) + list(split[\"valid\"][\"Drug\"]))\n",
    "train_halflives = np.array(list(split[\"train\"][\"Y\"]) + list(split[\"valid\"][\"Y\"]))\n",
    "test_smiles = np.array(list(split[\"test\"][\"Drug\"]) + list(split[\"test\"][\"Drug\"]))\n",
    "test_halflives = np.array(list(split[\"test\"][\"Y\"]) + list(split[\"test\"][\"Y\"]))\n",
    "\n",
    "reshaped_train_halflife = np.array(train_halflives).reshape(-1, 1)\n",
    "scaler = MinMaxScaler().fit(reshaped_train_halflife)\n",
    "train_halflife_scaled = scaler.transform(reshaped_train_halflife)\n",
    "train_halflives_scaled = np.array([val[0] for val in train_halflife_scaled])\n",
    "\n",
    "reshaped_test_halflife = np.array(test_halflives).reshape(-1, 1)\n",
    "scaler = MinMaxScaler().fit(reshaped_test_halflife)\n",
    "test_halflife_scaled = scaler.transform(reshaped_test_halflife)\n",
    "test_halflives_scaled = np.array([val[0] for val in test_halflife_scaled])\n",
    "\n",
    "print(train_smiles.shape, train_halflives_scaled.shape, test_smiles.shape, test_halflives_scaled.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1ea4233e-990d-4090-8fbc-5f52e2aad59b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[20:04:25] UFFTYPER: Unrecognized charge state for atom: 18\n",
      "[20:04:39] UFFTYPER: Unrecognized charge state for atom: 1\n"
     ]
    }
   ],
   "source": [
    "train_jazzy_fps = []\n",
    "train_jazzy_thalfs = []\n",
    "test_jazzy_fps = []\n",
    "test_jazzy_thalfs = []\n",
    "\n",
    "for smi, thalf in zip(train_smiles, train_halflives_scaled):\n",
    "    try:\n",
    "        jazzy_fp = mol_vect(smi)\n",
    "    except:\n",
    "        jazzy_fp = None\n",
    "    if jazzy_fp and not np.isnan(np.array(list(jazzy_fp.values()))).any():\n",
    "        jazzy_fp_list = np.array([fp for fp in jazzy_fp.values()])\n",
    "        train_jazzy_fps.append(jazzy_fp_list)\n",
    "        train_jazzy_thalfs.append(thalf)\n",
    "\n",
    "for smi, thalf in zip(test_smiles, test_halflives_scaled):\n",
    "    try:\n",
    "        jazzy_fp = mol_vect(smi)\n",
    "    except:\n",
    "        jazzy_fp = None\n",
    "    if jazzy_fp and not np.isnan(np.array(list(jazzy_fp.values()))).any():\n",
    "        jazzy_fp_list = np.array([fp for fp in jazzy_fp.values()])\n",
    "        test_jazzy_fps.append(jazzy_fp_list)\n",
    "        test_jazzy_thalfs.append(thalf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b29b6623-4e4b-4604-9bb4-c049477bbcc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(970, 6) (970,) (486, 6) (486,)\n"
     ]
    }
   ],
   "source": [
    "train_jazzy_fps = np.array(train_jazzy_fps)\n",
    "train_jazzy_thalfs = np.array(train_jazzy_thalfs)\n",
    "test_jazzy_fps = np.array(test_jazzy_fps)\n",
    "test_jazzy_thalfs = np.array(test_jazzy_thalfs)\n",
    "print(train_jazzy_fps.shape, train_jazzy_thalfs.shape, test_jazzy_fps.shape, test_jazzy_thalfs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a6acd225-aaa5-4a91-b739-b9e363fc9672",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(970, 124) (486, 124)\n"
     ]
    }
   ],
   "source": [
    "train_morgan_fps = np.array(fp_from_smiles(train_smiles))\n",
    "test_morgan_fps = np.array(fp_from_smiles(test_smiles))\n",
    "print(train_morgan_fps.shape, test_morgan_fps.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "97790a0b-e45d-4e0f-9c58-e216e688a344",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "_ParzenEstimatorParameters.__new__() missing 1 required positional argument: 'categorical_distance_func'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m     best_model_hyperparams[_type] \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m model_id \u001b[38;5;129;01min\u001b[39;00m model_identifiers:\n\u001b[1;32m----> 5\u001b[0m         jl \u001b[38;5;241m=\u001b[39m joblib\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mproject_resources/optuna/obach/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.pkl\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      6\u001b[0m         best_model_hyperparams[_type][model_id] \u001b[38;5;241m=\u001b[39m jl\u001b[38;5;241m.\u001b[39mbest_trial\u001b[38;5;241m.\u001b[39mparams\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(best_model_hyperparams[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmorgan\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlinear\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\it4i\\Lib\\site-packages\\joblib\\numpy_pickle.py:658\u001b[0m, in \u001b[0;36mload\u001b[1;34m(filename, mmap_mode)\u001b[0m\n\u001b[0;32m    652\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(fobj, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    653\u001b[0m                 \u001b[38;5;66;03m# if the returned file object is a string, this means we\u001b[39;00m\n\u001b[0;32m    654\u001b[0m                 \u001b[38;5;66;03m# try to load a pickle file generated with an version of\u001b[39;00m\n\u001b[0;32m    655\u001b[0m                 \u001b[38;5;66;03m# Joblib so we load it with joblib compatibility function.\u001b[39;00m\n\u001b[0;32m    656\u001b[0m                 \u001b[38;5;28;01mreturn\u001b[39;00m load_compatibility(fobj)\n\u001b[1;32m--> 658\u001b[0m             obj \u001b[38;5;241m=\u001b[39m _unpickle(fobj, filename, mmap_mode)\n\u001b[0;32m    659\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obj\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\it4i\\Lib\\site-packages\\joblib\\numpy_pickle.py:577\u001b[0m, in \u001b[0;36m_unpickle\u001b[1;34m(fobj, filename, mmap_mode)\u001b[0m\n\u001b[0;32m    575\u001b[0m obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    576\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 577\u001b[0m     obj \u001b[38;5;241m=\u001b[39m unpickler\u001b[38;5;241m.\u001b[39mload()\n\u001b[0;32m    578\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m unpickler\u001b[38;5;241m.\u001b[39mcompat_mode:\n\u001b[0;32m    579\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe file \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m has been generated with a \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    580\u001b[0m                       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjoblib version less than 0.10. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    581\u001b[0m                       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease regenerate this pickle file.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    582\u001b[0m                       \u001b[38;5;241m%\u001b[39m filename,\n\u001b[0;32m    583\u001b[0m                       \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\it4i\\Lib\\pickle.py:1213\u001b[0m, in \u001b[0;36m_Unpickler.load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1211\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEOFError\u001b[39;00m\n\u001b[0;32m   1212\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, bytes_types)\n\u001b[1;32m-> 1213\u001b[0m         dispatch[key[\u001b[38;5;241m0\u001b[39m]](\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m   1214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _Stop \u001b[38;5;28;01mas\u001b[39;00m stopinst:\n\u001b[0;32m   1215\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m stopinst\u001b[38;5;241m.\u001b[39mvalue\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\it4i\\Lib\\pickle.py:1514\u001b[0m, in \u001b[0;36m_Unpickler.load_newobj\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1512\u001b[0m args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstack\u001b[38;5;241m.\u001b[39mpop()\n\u001b[0;32m   1513\u001b[0m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstack\u001b[38;5;241m.\u001b[39mpop()\n\u001b[1;32m-> 1514\u001b[0m obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__new__\u001b[39m(\u001b[38;5;28mcls\u001b[39m, \u001b[38;5;241m*\u001b[39margs)\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mappend(obj)\n",
      "\u001b[1;31mTypeError\u001b[0m: _ParzenEstimatorParameters.__new__() missing 1 required positional argument: 'categorical_distance_func'"
     ]
    }
   ],
   "source": [
    "best_model_hyperparams = {}\n",
    "for _type in feature_types:\n",
    "    best_model_hyperparams[_type] = {}\n",
    "    for model_id in model_identifiers:\n",
    "        jl = joblib.load(f\"project_resources/optuna/AZ_Microsome/{_type}/{model_id}.pkl\")\n",
    "        best_model_hyperparams[_type][model_id] = jl.best_trial.params\n",
    "print(best_model_hyperparams[\"morgan\"][\"linear\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e5f01f8-c049-4854-8988-25dda84036c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predicted = {}\n",
    "rmsds = {}\n",
    "stds = {}\n",
    "best_models = {}\n",
    "# test models with the best hyperparams\n",
    "for _type in feature_types:\n",
    "    y_predicted[_type] = {}\n",
    "    rmsds[_type] = {}\n",
    "    stds[_type] = {}\n",
    "    best_models[_type] = {}\n",
    "    group_rmsds = {}\n",
    "    for model_id in model_identifiers:\n",
    "        hyperparams = best_model_hyperparams[_type][model_id]\n",
    "        if _type == \"morgan\":\n",
    "            X_train = train_morgan_fps\n",
    "            y_train = train_halflives_scaled\n",
    "            X_test = test_morgan_fps\n",
    "            y_test = test_halflives_scaled\n",
    "\n",
    "        elif _type == \"jazzy\":\n",
    "            X_train = train_jazzy_fps\n",
    "            y_train = train_jazzy_thalfs\n",
    "            X_test = test_jazzy_fps\n",
    "            y_test = test_jazzy_thalfs\n",
    "\n",
    "        if model_id == 'linear':\n",
    "            alpha = hyperparams[\"alpha\"]\n",
    "            l1_ratio = hyperparams[\"l1_ratio\"]\n",
    "            reg = ElasticNet(alpha=alpha, l1_ratio=l1_ratio, fit_intercept=True)\n",
    "\n",
    "        if model_id == 'KRR':\n",
    "            alpha = hyperparams[\"alpha\"]\n",
    "            gamma = hyperparams[\"gamma\"]\n",
    "            kernel = hyperparams[\"kernel\"]\n",
    "            reg = KernelRidge(alpha=alpha, gamma=gamma, kernel=kernel)\n",
    "\n",
    "        if model_id == 'GB':\n",
    "            n_estimators = hyperparams[\"n_estimators\"]\n",
    "            learning_rate = hyperparams[\"learning_rate\"]\n",
    "            max_depth = hyperparams[\"max_depth\"]\n",
    "            reg = GradientBoostingRegressor(n_estimators=n_estimators, learning_rate=learning_rate, max_depth=max_depth)\n",
    "\n",
    "        if model_id == 'RF':\n",
    "            n_estimators = hyperparams[\"n_estimators\"]\n",
    "            max_features = hyperparams[\"max_features\"]\n",
    "            max_depth = hyperparams[\"max_depth\"]\n",
    "            reg = RandomForestRegressor(n_estimators=n_estimators, max_features=max_features, max_depth=max_depth)\n",
    "\n",
    "        if model_id == 'ANN':\n",
    "            learning_rate_init = hyperparams[\"learning_rate_init\"]\n",
    "            hidden_layer_sizes = hyperparams[\"hidden_layer_sizes\"]\n",
    "            reg = MLPRegressor(learning_rate_init=learning_rate_init, hidden_layer_sizes=hidden_layer_sizes)\n",
    "\n",
    "        # create an instance of HyperparamTuner without specifying any model_identifier\n",
    "        tuner = HyperparamTuner(\"foo\", X_train, y_train, X_test, y_test)\n",
    "        # and use the train_test_return function with return_predictions to get the rmsd values\n",
    "        # average over multiple runs of the same model\n",
    "        runs_rmsds = []\n",
    "        runs_y_test_predictions = []\n",
    "        runs_stds = []\n",
    "        for i in range(10):\n",
    "            rmsd, y_test_predictions, std = tuner.train_test_return(\"foo\", reg, return_predictions=True)\n",
    "            runs_rmsds.append(rmsd)\n",
    "            runs_y_test_predictions.append(y_test_predictions)\n",
    "            runs_stds.append(std)\n",
    "        mean_rmsd = np.mean(runs_rmsds, axis=0)\n",
    "        mean_y_test_predictions = np.mean(runs_y_test_predictions, axis=0)\n",
    "        mean_stds = np.mean(runs_stds, axis=0)\n",
    "        group_rmsds[mean_rmsd] = model_id\n",
    "        rmsds[_type][model_id] = mean_rmsd\n",
    "        y_predicted[_type][model_id] = mean_y_test_predictions\n",
    "        stds[_type][model_id] = mean_stds\n",
    "        print(mean_rmsd, f\"y_test predictions: {y_test_predictions[:5]}, {len(y_test_predictions)}\")\n",
    "        print(f\"     standard deviations: {mean_stds[:4]}, {len(mean_stds)}\")\n",
    "\n",
    "    # find best model for each dataset and its rmsd\n",
    "    min_rmsd = min(group_rmsds.keys())\n",
    "    best_model = group_rmsds[min_rmsd]\n",
    "    best_models[_type] = (best_model, min_rmsd)\n",
    "    print(f\"best was {best_model} with rmsd {min_rmsd}\")\n",
    "\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c6c0909-1414-42c4-b96d-1fbc02204b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tanimoto_similarities = tanimoto(test_morgan_fps, train_morgan_fps)\n",
    "median = np.median(tanimoto_similarities)\n",
    "mean = np.mean(tanimoto_similarities)\n",
    "print(f\"length: {len(tanimoto_similarities)}, median: {median}, arithmetic mean: {mean}, \",\n",
    "      tanimoto_similarities[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44e971a2-05be-4286-9c52-04bb76853b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = best_models[\"morgan\"][0]\n",
    "create_interactive_scatter_plot(tanimoto_similarities, y_predicted[\"morgan\"][model_id],\n",
    "                                \"Tanimoto Similarity\", \"Predicted Test Half-life\",\n",
    "                                \"Obach Tanimoto Similartiy Between Test and Train\", \"Molecular Similarity vs. Predicted Values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f178adb-2133-4abd-94f2-7b7d1e2bc575",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = best_models[\"morgan\"][0]\n",
    "create_interactive_scatter_plot(test_halflives_scaled, y_predicted[\"morgan\"][model_id],\n",
    "                                \"Real Test Half-life\", \"Predicted Test Half-life\",\n",
    "                                f\"Prediction of the Obach Dataset Using {model_id} on the Morgan Fingerprints\",\n",
    "                                \"Real vs. Predicted Values\", include_diagonal=True, y_error=stds[\"morgan\"][model_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a4aa91-e16a-4d07-831e-6bbce61da588",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = best_models[\"jazzy\"][0]\n",
    "create_interactive_scatter_plot(test_halflives_scaled, y_predicted[\"jazzy\"][model_id],\n",
    "                                \"Real Test Half-life\", \"Predicted Test Half-life\",\n",
    "                                f\"Prediction of the Obach Dataset Using {model_id} on the Jazzy Fingerprints\",\n",
    "                                \"Real vs. Predicted Values\", include_diagonal=True, y_error=stds[\"jazzy\"][model_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "300fb467-52cf-4d41-9e43-6901266648c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(train_halflives_scaled)\n",
    "plt.hist(train_halflives_scaled, range=(0, 0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4c545f5-e198-4b1c-8425-ac629675ca56",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(train_halflives_scaled, range=(0, 0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "289f56c6-142b-4ade-a099-ca9e2c7c3db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(test_halflives_scaled)\n",
    "plt.hist(train_halflives_scaled, range=(0, 0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3198de9e-cbff-4f0f-a690-950d92ca6d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(test_halflives_scaled, range=(0, 0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a937a7e-6b32-4bc2-a839-a747820e9c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = best_models[\"morgan\"][0]\n",
    "print(\"morgan\")\n",
    "print(spearmanr(test_halflives_scaled, y_predicted[\"morgan\"][model_id]))\n",
    "print(\"R^2 score:\", r2_score(test_halflives_scaled, y_predicted[\"morgan\"][model_id]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7da6b4f-bd24-4ee0-9dd5-8d7ec0404108",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = best_models[\"jazzy\"][0]\n",
    "print(\"jazzy\")\n",
    "print(spearmanr(test_jazzy_thalfs, y_predicted[\"jazzy\"][model_id]))\n",
    "print(\"R^2 score:\", r2_score(test_jazzy_thalfs, y_predicted[\"jazzy\"][model_id]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf7c5a7b-fb4e-4615-8e3f-46e805808fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = samplers['TPESampler']\n",
    "pruner = pruners[\"BasePruner\"]\n",
    "n_trials = 200\n",
    "with ThreadPoolExecutor() as executor:\n",
    "    futures = []\n",
    "    for _type in feature_types:\n",
    "        if _type == \"morgan\":\n",
    "            X_train = train_morgan_fps\n",
    "            y_train = train_halflives_scaled\n",
    "            X_test = test_morgan_fps\n",
    "            y_test = test_halflives_scaled\n",
    "\n",
    "        elif _type == \"jazzy\":\n",
    "            X_train = train_jazzy_fps\n",
    "            y_train = train_jazzy_thalfs\n",
    "            X_test = test_jazzy_fps\n",
    "            y_test = test_jazzy_thalfs\n",
    "\n",
    "        for model_identifier in model_identifiers:\n",
    "            print(model_identifier)\n",
    "            lock_obj = optuna.storages.JournalFileOpenLock(\n",
    "                f\"./project_resources/optuna/AZ_Microsome/{_type}/{model_identifier}_journal.log\"\n",
    "            )\n",
    "\n",
    "            storage = JournalStorage(\n",
    "                            JournalFileStorage(f\"./project_resources/optuna/AZ_Microsome/{_type}/{model_identifier}_journal.log\", lock_obj=lock_obj)\n",
    "                        )\n",
    "            study = optuna.create_study(study_name=model_identifier, directions=['minimize'], pruner=pruner,\n",
    "                                        storage=storage, load_if_exists=True)\n",
    "            tuner = HyperparamTuner(model_identifier, X_train, y_train, X_test, y_test)\n",
    "            futures.append(executor.submit(study.optimize, tuner.objective, n_trials=n_trials))\n",
    "            joblib.dump(study, f\"./project_resources/optuna/AZ_Microsome/{_type}/{model_identifier}.pkl\")\n",
    "    for future in futures:\n",
    "        future.result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e1894f-c39b-4515-9aec-a11d1e989cf4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
