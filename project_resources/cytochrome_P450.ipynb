{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c9008c0c-217a-4a82-8efa-1bdd0d28a545",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import warnings\n",
    "from chembl_webresource_client.new_client import new_client as client\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit.Chem.MolStandardize.rdMolStandardize import FragmentParent\n",
    "from rdkit import DataStructs\n",
    "from jazzy.api import molecular_vector_from_smiles as mol_vect\n",
    "import numpy as np\n",
    "import pubchempy as pcp\n",
    "import matplotlib.pyplot as plt\n",
    "import pathlib\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn import linear_model\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import ShuffleSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ddc091cb-0b13-470e-af3c-59c794cd6005",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "22e6b12d-890c-41ce-8611-9ea45d8466fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "working_dir = os.getcwd()\n",
    "# dir for useful stuff for the actual essay\n",
    "graphs_rel_path = r\"project_results/graphs\"\n",
    "project_results_graphs = os.path.join(working_dir, graphs_rel_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "230cfb56-2882-490c-a465-d3d816c4488f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def abs_file_path(rel_path):\n",
    "    working_dir = os.getcwd()\n",
    "    abs_file_path = os.path.join(working_dir, rel_path.replace(\"\\\\\", \"/\"))\n",
    "    return abs_file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c381d76-cdf3-44f5-aec4-ccec30e5fa15",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def smiles_from_mol_id(list_mol_id):\n",
    "    # returns a list of smiles strings for given list of mol ids\n",
    "    list_smiles = []\n",
    "    if \"CHEMBL\" in str(list_mol_id):\n",
    "        for chembl_id in list_mol_id:\n",
    "            molecule = client.molecule\n",
    "            compound = molecule.filter(chembl_id=chembl_id)[0]\n",
    "            list_smiles.append(compound['molecule_structures'][\"canonical_smiles\"])\n",
    "    else:\n",
    "        for cid in list_mol_id:\n",
    "            compound = pcp.Compound.from_cid(cid)\n",
    "            smiles = compound.isomeric_smiles\n",
    "            list_smiles.append(smiles)\n",
    "    return list_smiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "969e73cd-b678-4f29-9593-4526f26255fc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def halflife_formatting(source_df, isozyme):\n",
    "    # creates a correctly formatted list of half-life values from df\n",
    "    list_halflife = []\n",
    "    if isozyme == \"3A4\":\n",
    "        df_adjusted = source_df\n",
    "        list_halflife = df_adjusted[\"Standard Value\"]\n",
    "    if isozyme == \"RLM\":\n",
    "        df_adjusted = source_df.replace({\">30\": '30'})\n",
    "        list_halflife = df_adjusted[\"Half-life (minutes)\"]\n",
    "    if isozyme == \"HLC\":\n",
    "        df_adjusted = source_df\n",
    "        list_halflife = df_adjusted[\"Half-life\"]\n",
    "    return list_halflife"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d723ee2-cd0c-449d-9c77-855f047c75a1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def isz_csv_data_formatting(source_csv_file, isozyme, sep=\",\"):\n",
    "    # inputs are relative paths\n",
    "    # creates a correctly formatted csv file for use with the chemprop library\n",
    "    source_df = pd.read_csv(abs_file_path(source_csv_file), sep=sep)\n",
    "\n",
    "    if isozyme + \".csv\" in os.listdir(abs_file_path(\"project_resources\")):\n",
    "        print(f\"{isozyme}.csv already exists in dir\")\n",
    "    else:\n",
    "        if isozyme == \"3A4\":\n",
    "            # additional formatting, since not all molecules have the desired property\n",
    "            source_df = source_df[source_df[\"Standard Type\"] == \"T1/2\"]\n",
    "        try:\n",
    "            mol_ids = source_df[\"Molecule ChEMBL ID\"]\n",
    "        except KeyError:\n",
    "            mol_ids = source_df[\"PUBCHEM_CID\"]\n",
    "        final_df = pd.DataFrame()\n",
    "        final_df[\"mol_idx\"] = list(range(1, len(mol_ids)+1))\n",
    "        orig_smiles = smiles_from_mol_id(mol_ids)\n",
    "        cleaned_smiles = []\n",
    "        # replace smiles with two disjoint parts with only the bigger mol\n",
    "        for smi in orig_smiles:\n",
    "            mol = Chem.MolFromSmiles(smi)\n",
    "            cleaned_mol = FragmentParent(mol)\n",
    "            cleaned_smi = Chem.MolToSmiles(cleaned_mol)\n",
    "            cleaned_smiles.append(cleaned_smi)\n",
    "        final_df[\"smiles\"] = cleaned_smiles\n",
    "        final_df[\"half-life\"] = list(halflife_formatting(source_df, isozyme))\n",
    "        final_df.to_csv(abs_file_path(f\"project_resources/{isozyme}.csv\"), index=False)\n",
    "        print(f\"{isozyme}.csv was successfully created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "edb562e5-1b30-4f60-9556-cc1e7eacb33f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_csv_data_formatting(isozyme, smiles_as_index, split_smiles, split_type):\n",
    "    # saves ML splits as csv files containing mol idxs, smiles and half-lives\n",
    "    for split in [\"train\", \"test\"]:\n",
    "        location = f\"project_resources/data_splits/{split_type}\"\n",
    "        file_name = f\"{isozyme}_{split}.csv\"\n",
    "        # check if file already exists\n",
    "        try:\n",
    "            with open(f\"{location}/{file_name}\") as f:\n",
    "                f.close()\n",
    "            print(f\"{file_name} already exists in {location}\")\n",
    "\n",
    "        except FileNotFoundError:\n",
    "            split_df = pd.DataFrame()\n",
    "            split_indexes = []\n",
    "            split_halflifes = []\n",
    "            isz_scaff_split_smiles = split_smiles[split]\n",
    "\n",
    "            # get the index and half-life values for each smiles in data split\n",
    "            for smi in isz_scaff_split_smiles:\n",
    "                smi_idx = smiles_as_index[isozyme][smi][0]  # numerical index of smiles\n",
    "                split_indexes.append(smi_idx)\n",
    "                mol_halflife = smiles_as_index[isozyme][smi][1]  # half-life value for the specific molecule\n",
    "                split_halflifes.append(mol_halflife)\n",
    "\n",
    "            split_df[\"index\"] = split_indexes\n",
    "            split_df[\"smiles\"] = isz_scaff_split_smiles\n",
    "            split_df[\"half-life\"] = split_halflifes\n",
    "            split_df.to_csv(abs_file_path(f\"{location}/{file_name}\"), index=False)\n",
    "            print(f\"{file_name} was successfully created in {location}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0d7d951f-ec96-4980-ba4a-327bdb7675da",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def fp_from_smiles(list_smiles):\n",
    "    list_fingerprint = []\n",
    "    for smi in list_smiles:\n",
    "        mol = Chem.MolFromSmiles(smi)\n",
    "        fingerprint = AllChem.GetMorganFingerprintAsBitVect(mol, useChirality=True, radius=2, nBits = 124)\n",
    "        vector = np.array(fingerprint)\n",
    "        list_fingerprint.append(vector)\n",
    "    # takes a list of smiles strings,output is a corresponding Morgan fingerprint as a list\n",
    "    return list_fingerprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c08b28f-16cc-4bfb-90a7-f2622de07cda",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_scatter_plot(x_axis, y_axis, plot_title, x_label, y_label, diag=False, error_bars=False, x_min=None, y_min=None, x_max=None, y_max=None, save_dir=None, save_file_name=None):\n",
    "    # !!! perhaps shorten input of function by using a class?\n",
    "    # x_axis, y_axis ... input values to be displayed on their respective axis\n",
    "    # x_min, y_min, x_max, y_max ... decide the span of the graph\n",
    "    plt.scatter(x_axis, y_axis, edgecolors=None, c='b', alpha=0.2)\n",
    "    if diag:\n",
    "        diag = np.linspace(x_min, x_max)\n",
    "        plt.plot(diag, diag, linestyle='dotted')\n",
    "    plt.xlim(x_min, x_max)\n",
    "    plt.ylim(y_min, y_max)\n",
    "    plt.ylabel(y_label)\n",
    "    plt.xlabel(x_label)\n",
    "    plt.suptitle(plot_title)\n",
    "    if save_dir and save_file_name:\n",
    "        plt.savefig(os.path.join(save_dir, save_file_name))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "56d699bd-3b9b-49ca-be5e-b6e000a065f4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def to_rdkit_fingerprint(fps):\n",
    "    rdkit_fingerprints = []\n",
    "    for prnt in fps:\n",
    "        bitstring = \"\".join(prnt.astype(str))\n",
    "        fp = DataStructs.cDataStructs.CreateFromBitString(bitstring)\n",
    "        rdkit_fingerprints.append(fp)\n",
    "    return rdkit_fingerprints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8519f105-50fe-44cb-89f5-d08a48ccf5dc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def tanimoto(fps, fp2s):\n",
    "    tanimoto_similarities = []\n",
    "    fps = to_rdkit_fingerprint(fps)\n",
    "    fp2s = to_rdkit_fingerprint(fp2s)\n",
    "    for x in fps:\n",
    "        fpsx = []\n",
    "        for y in fp2s:\n",
    "            fpsx.append(DataStructs.TanimotoSimilarity(x, y))\n",
    "        max_tanimoto = max(fpsx)\n",
    "        tanimoto_similarities.append(round(max_tanimoto, 3))\n",
    "    print(tanimoto_similarities[:25], f\"length: {len(tanimoto_similarities)}\")\n",
    "    return tanimoto_similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "239c2f81-6aa3-48ae-86f6-5c879f6780be",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def param_tuning(x_train, x_test, y_train, y_test, type_ml_use):\n",
    "    # !!! určování hodnot pro param tuning, lze vylepšit pomocí np.random.randint\n",
    "\n",
    "    if type_ml_use == 'linear':\n",
    "        param_grid = {\n",
    "            'fit_intercept': [True],\n",
    "            'alpha': [1e-5, 1e-4, 1e-3, 1e-2],\n",
    "            'l1_ratio': [0, 0.1, 0.5, 0.9, 1]\n",
    "        }\n",
    "        reg = linear_model.ElasticNet()\n",
    "\n",
    "    if type_ml_use == 'KRR':\n",
    "        param_grid = {\n",
    "            \"alpha\": np.logspace(-4, 1, 20),\n",
    "            \"gamma\": np.logspace(-14, 0, 20),\n",
    "            \"kernel\": ['linear', 'laplacian', 'rbf']\n",
    "        }\n",
    "        reg = KernelRidge()\n",
    "\n",
    "    if type_ml_use == 'GB':\n",
    "        param_grid = {\n",
    "            'n_estimators': [10, 20, 50, 200, 400],\n",
    "            'learning_rate': [0.02, 0.05],\n",
    "            'max_depth': [1, 2, 3, 5],\n",
    "        }\n",
    "        reg = GradientBoostingRegressor()\n",
    "\n",
    "    if type_ml_use == 'RF':\n",
    "        param_grid = {\n",
    "            'max_depth': [None, 2, 3, 5, 10],\n",
    "            'max_features': ['auto', 'sqrt', 'log2'],\n",
    "            'n_estimators': [10, 20, 50, 100, 200],\n",
    "        }\n",
    "        reg = RandomForestRegressor()\n",
    "\n",
    "    if type_ml_use == 'ANN':\n",
    "        param_grid = {\n",
    "            'learning_rate_init': [0.001, 0.002, 0.005, 0.01, 0.02, 0.05],\n",
    "            'hidden_layer_sizes': [[5], [10], [20], [50], [5]*2, [10]*2, [20]*2, [50]*2, [5]*3, [10]*3]\n",
    "        }\n",
    "        reg = MLPRegressor()\n",
    "\n",
    "    grid = RandomizedSearchCV(reg, param_grid, cv=KFold(n_splits=5, shuffle=True), verbose=0)\n",
    "    grid.fit(x_train, y_train)\n",
    "    best_reg = grid.best_estimator_\n",
    "    y_train_predict = best_reg.predict(x_train)\n",
    "    y_test_predict = best_reg.predict(x_test)\n",
    "    abs_error = np.abs(y_test_predict-y_test)\n",
    "    print(f\"     best {type_ml_use} hyperparams: {best_reg}\")\n",
    "    # retrain on best hyperparameters\n",
    "    best_reg.fit(x_train, y_train)\n",
    "\n",
    "    return y_train_predict, y_test_predict, abs_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a670f02b-9788-46fa-b641-bdcba9445350",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def mol_predict_and_std(models, x_train, x_test, y_train, y_test):\n",
    "    y_test_avg_predict_dict = {}\n",
    "    std_dict = {}\n",
    "    rmsd_dict = {}\n",
    "    for model in models:\n",
    "        y_test_predicts = []\n",
    "\n",
    "        for i in range(3):\n",
    "            asdf, y_test_predict, ghjk = param_tuning(x_train, x_test, y_train, y_test, model)\n",
    "            # asdf, ghjk ... dummy variables, are not needed here\n",
    "            y_test_predicts.append(y_test_predict)\n",
    "\n",
    "        y_test_predicts_array = np.array(y_test_predicts)\n",
    "\n",
    "        y_test_avg_predict = np.average(y_test_predicts_array, axis=0)\n",
    "        standard_deviation = np.std(y_test_predicts_array, axis=0)\n",
    "        rmsd = np.sqrt(np.average(np.square(y_test_avg_predict-y_test)))\n",
    "        # root-mean-square deviation\n",
    "\n",
    "        y_test_avg_predict_dict[model] = y_test_avg_predict\n",
    "        std_dict[model] = standard_deviation\n",
    "        rmsd_dict[model] = rmsd\n",
    "    return y_test_avg_predict_dict, std_dict, rmsd_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1e49f942-3694-4bd5-912c-6abeec5864ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CODE SPECIFIC TO JAZZY:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7baac92b-d38c-4e5d-afbf-4f14ab6f144a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mol_fts(smiles, isozyme):\n",
    "    features = []\n",
    "    for smi in smiles:\n",
    "        try:\n",
    "            features.append(mol_vect(smi))\n",
    "        except Exception as e:\n",
    "            # nepřišel jsem na to, jak zachytit ten JazzyError - protože mi to napíše NameError: name 'JazzyError' is not defined\n",
    "            print(f\"{e} caused by {smi}\")\n",
    "            features.append(np.nan)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2bf09b11-afa9-40bd-897e-b81f331b39ee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# CODE SPECIFIC TO NEQUIP:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cdad295a-c2f7-40cf-8ae9-5527b0d93815",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def list_splitter(list_to_split, ratio):\n",
    "    elements = len(list_to_split)\n",
    "    middle = int(elements * ratio)\n",
    "    return [list_to_split[:middle], list_to_split[middle:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "17d4cc5e-c090-4a24-b2e7-ddc020487e60",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_atom_chars(smi):\n",
    "    atoms_chars = []\n",
    "    mol = Chem.MolFromSmiles(smi, sanitize=False)\n",
    "    for a in mol.GetAtoms():\n",
    "        atom = Chem.RWMol()\n",
    "        atom.AddAtom(a)\n",
    "        atom_smiles = Chem.MolToSmiles(atom)\n",
    "        atom_smiles = str(atom_smiles)\n",
    "        atoms_chars.append(atom_smiles)\n",
    "    return atoms_chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "633fe58f-db07-4141-ab4a-74f48a1e6606",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unique_symbols(list_smiles):\n",
    "    # gets unique symbols from every mol in the list e.g. [\"C1=CC=C(C=C1)O\", \"C1=CSC=C1\"] -> [\"C\", \"O\", \"S\"]\n",
    "    all_smiles = \"\"  # every smiles together in one string\n",
    "    for smiles in list_smiles:\n",
    "        all_smiles += smiles\n",
    "    atoms = get_atom_chars(all_smiles)  # all atoms present in the smiles e.g. \"C1=CSC=C1\" -> [\"C\", \"C\", \"S\", \"C\", \"C\"]\n",
    "    unique_symbols_set = set(atoms)  # remove duplicates\n",
    "    unique_symbols = list(unique_symbols_set)\n",
    "    unique_symbols = [sym for sym in unique_symbols if \"[\" not in sym]  # filter out isotopes and ions, both of which are in brackets\n",
    "    # filter out lower case letters (.upper method is not viable, since some elements have more than one letter e.g. He)\n",
    "    unique_symbols = [sym for sym in unique_symbols if sym[0].isupper()]\n",
    "    return unique_symbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9a263bc-ae56-42b2-bd1f-59dd4bf34397",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
