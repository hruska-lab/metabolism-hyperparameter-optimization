{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c9008c0c-217a-4a82-8efa-1bdd0d28a545",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import warnings\n",
    "from chembl_webresource_client.new_client import new_client as client\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit import DataStructs\n",
    "import numpy as np\n",
    "import pubchempy as pcp\n",
    "import matplotlib.pyplot as plt\n",
    "import pathlib\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn import linear_model\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import ShuffleSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ddc091cb-0b13-470e-af3c-59c794cd6005",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "22e6b12d-890c-41ce-8611-9ea45d8466fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "working_dir = os.getcwd()\n",
    "# dir for useful stuff for the actual essay\n",
    "graphs_rel_path = r\"project_results/graphs\"\n",
    "project_results_graphs = os.path.join(working_dir, graphs_rel_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "230cfb56-2882-490c-a465-d3d816c4488f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def abs_file_path(rel_path):\n",
    "    working_dir = os.getcwd()\n",
    "    abs_file_path = os.path.join(working_dir, rel_path.replace(\"\\\\\", \"/\"))\n",
    "    return abs_file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d1a6e85-c77e-4488-8377-7a8e8660ba4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def smiles_from_mol_id(list_mol_id, database, isozyme):\n",
    "    list_smiles = []\n",
    "    smiles_csv_rel = r\"project_resources/smiles.csv\"\n",
    "    smiles_csv_abs = os.path.join(working_dir, smiles_csv_rel)\n",
    "\n",
    "    # Check if SMILES CSV file exists\n",
    "    if not pathlib.Path(smiles_csv_abs).is_file():\n",
    "        with open(smiles_csv_abs, \"w\") as empty_csv:\n",
    "            pass\n",
    "        smiles_csv = pd.DataFrame()\n",
    "    else:\n",
    "        # Read SMILES CSV file\n",
    "        smiles_csv = pd.read_csv(smiles_csv_abs, index_col=0)\n",
    "\n",
    "    try:\n",
    "        list_smiles = smiles_csv[isozyme].values\n",
    "    except KeyError or ValueError:\n",
    "        if database == \"ChEMBL\":\n",
    "            for chembl_id in list_mol_id:\n",
    "                molecule = client.molecule\n",
    "                compound = molecule.filter(chembl_id=chembl_id)[0]\n",
    "                list_smiles.append(compound['molecule_structures'][\"canonical_smiles\"])\n",
    "\n",
    "        if database == \"PubChem\":\n",
    "            for cid in list_mol_id:\n",
    "                compound = pcp.Compound.from_cid(cid)\n",
    "                smiles = compound.isomeric_smiles\n",
    "                list_smiles.append(smiles)\n",
    "\n",
    "        # Check if the isozyme exists in the DataFrame\n",
    "        if isozyme not in smiles_csv.columns:\n",
    "            smiles_csv[isozyme] = \"\"\n",
    "\n",
    "        # Create a dictionary of {index: smile} pairs\n",
    "        smile_dict = {i: smile for i, smile in enumerate(list_smiles)}\n",
    "\n",
    "        # Assign the new smiles to the isozyme column\n",
    "        smiles_csv[isozyme].update(pd.Series(smile_dict))\n",
    "\n",
    "        smiles_csv.to_csv(smiles_csv_abs, index=True)  # Save DataFrame with index\n",
    "\n",
    "    final = []\n",
    "    for smile in list_smiles:\n",
    "        if smile == smile:  # Check for NaN values\n",
    "            final.append(smile)\n",
    "\n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0d7d951f-ec96-4980-ba4a-327bdb7675da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fp_from_smiles(list_smiles):\n",
    "    list_fingerprint = []\n",
    "    for smi in list_smiles:\n",
    "        mol = Chem.MolFromSmiles(smi)\n",
    "        fingerprint = AllChem.GetMorganFingerprintAsBitVect(mol, useChirality=True, radius=2, nBits = 124)\n",
    "        vector = np.array(fingerprint)\n",
    "        list_fingerprint.append(vector)\n",
    "    # takes a list of smiles strings,output is a corresponding Morgan fingerprint as a list\n",
    "    return list_fingerprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "510a4c07-4555-42db-aeb7-3b69b7f19edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def xy_split(fps_array, halflife, fps_arrays=False):\n",
    "    x = fps_array\n",
    "    y = halflife\n",
    "\n",
    "    idx_train, idx_test = train_test_split(np.arange(len(y)), test_size=0.2, random_state=42)\n",
    "\n",
    "    x_train = x[idx_train]\n",
    "    x_test = x[idx_test]\n",
    "\n",
    "    y_train = y[idx_train]\n",
    "    y_test = y[idx_test]\n",
    "\n",
    "    if fps_arrays:\n",
    "        fps_filtered_train = fps_array[idx_train]\n",
    "        fps_filtered_test = fps_array[idx_test]\n",
    "        return x_train, x_test, y_train, y_test, fps_filtered_train, fps_filtered_test\n",
    "\n",
    "    print(f\"shapes of variables ... fps array: {fps_array.shape}, halflife: {halflife.shape},\\n x_train: {x_train.shape}, x_test: {x_test.shape}, y_train: {y_train.shape}, y_test: {y_test.shape}\")\n",
    "    return x_train, x_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1c08b28f-16cc-4bfb-90a7-f2622de07cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_scatter_plot(x_axis, y_axis, plot_title, x_label, y_label, diag=False, error_bars=False, x_min=None, y_min=None, x_max=None, y_max=None, save_dir=None, save_file_name=None):\n",
    "    # !!! perhaps shorten input of function by using a class?\n",
    "    # !!! add error_bars after std has been fixed\n",
    "    # x_axis, y_axis ... input values to be displayed on their respective axis\n",
    "    # x_min, y_min, x_max, y_max ... decide the span of the graph\n",
    "    plt.scatter(x_axis, y_axis, edgecolors=None, c='b', alpha=0.2)\n",
    "    if diag:\n",
    "        diag = np.linspace(x_min, x_max)\n",
    "        plt.plot(diag, diag, linestyle='dotted')\n",
    "    if error_bars:\n",
    "        error_bars()\n",
    "    plt.xlim(x_min, x_max)\n",
    "    plt.ylim(y_min, y_max)\n",
    "    plt.ylabel(y_label)\n",
    "    plt.xlabel(x_label)\n",
    "    plt.suptitle(plot_title)\n",
    "    if save_dir and save_file_name:\n",
    "        plt.savefig(os.path.join(save_dir, save_file_name))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "56d699bd-3b9b-49ca-be5e-b6e000a065f4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def to_rdkit_fingerprint(fps):\n",
    "    rdkit_fingerprints = []\n",
    "    for prnt in fps:\n",
    "        bitstring = \"\".join(prnt.astype(str))\n",
    "        fp = DataStructs.cDataStructs.CreateFromBitString(bitstring)\n",
    "        rdkit_fingerprints.append(fp)\n",
    "    return rdkit_fingerprints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8519f105-50fe-44cb-89f5-d08a48ccf5dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tanimoto(fps, fp2s):\n",
    "    tanimoto_similarities = []\n",
    "    fps = to_rdkit_fingerprint(fps)\n",
    "    fp2s = to_rdkit_fingerprint(fp2s)\n",
    "    for x in fps:\n",
    "        fpsx = []\n",
    "        for y in fp2s:\n",
    "            fpsx.append(DataStructs.TanimotoSimilarity(x,y))\n",
    "        max_tanimoto = max(fpsx)\n",
    "        tanimoto_similarities.append(max_tanimoto)\n",
    "    print(tanimoto_similarities[:25], f\"length: {len(tanimoto_similarities)}\")\n",
    "    return tanimoto_similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "239c2f81-6aa3-48ae-86f6-5c879f6780be",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def param_tuning(x_train, x_test, y_train, y_test, type_ml_use, show_print=False):\n",
    "    # !!! určování hodnot pro param tuning, lze vylepšit pomocí np.random.randint\n",
    "\n",
    "    # !!! upravit linear hyperparams aby bylo lepší než před tuning\n",
    "\n",
    "    if type_ml_use == 'linear':\n",
    "        param_grid = {\n",
    "            'fit_intercept': [True],\n",
    "            'alpha': [1e-5, 1e-4, 1e-3, 1e-2],\n",
    "            'l1_ratio': [0, 0.1, 0.5, 0.9, 1]\n",
    "        }\n",
    "        reg = linear_model.ElasticNet()\n",
    "\n",
    "    if type_ml_use == 'KRR':\n",
    "        param_grid = {\n",
    "            \"alpha\": np.logspace(-4, 1, 20),\n",
    "            \"gamma\": np.logspace(-14, 0, 20),\n",
    "            \"kernel\": ['linear', 'laplacian', 'rbf']\n",
    "        }\n",
    "        reg = KernelRidge()\n",
    "\n",
    "    if type_ml_use == 'GB':\n",
    "        param_grid = {\n",
    "            'n_estimators': [10, 20, 50, 200, 400],\n",
    "            'learning_rate': [0.02, 0.05],\n",
    "            'max_depth': [1, 2, 3, 5],\n",
    "        }\n",
    "        reg = GradientBoostingRegressor()\n",
    "\n",
    "    if type_ml_use == 'RF':\n",
    "        param_grid = {\n",
    "            'max_depth': [None, 2, 3, 5, 10],\n",
    "            'max_features': ['auto', 'sqrt', 'log2'],\n",
    "            'n_estimators': [10, 20, 50, 100, 200],\n",
    "        }\n",
    "        reg = RandomForestRegressor()\n",
    "\n",
    "    if type_ml_use == 'ANN':\n",
    "        param_grid = {\n",
    "            'learning_rate_init': [0.001, 0.002, 0.005, 0.01, 0.02, 0.05],\n",
    "            'hidden_layer_sizes': [[5], [10], [20], [50], [5]*2, [10]*2, [20]*2, [50]*2, [5]*3, [10]*3]\n",
    "        }\n",
    "        reg = MLPRegressor()\n",
    "\n",
    "    grid = RandomizedSearchCV(reg, param_grid, cv=KFold(n_splits=5, shuffle=True), verbose=0)\n",
    "    grid.fit(x_train, y_train)\n",
    "    best_reg = grid.best_estimator_\n",
    "    y_train_predict = best_reg.predict(x_train)\n",
    "    y_test_predict = best_reg.predict(x_test)\n",
    "    abs_error = np.abs(y_test_predict-y_test)\n",
    "    print(f\"     best {type_ml_use} hyperparams: {best_reg}\")\n",
    "    # retrain on best hyperparameters\n",
    "    best_reg.fit(x_train, y_train)\n",
    "\n",
    "    return y_train_predict, y_test_predict, abs_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a670f02b-9788-46fa-b641-bdcba9445350",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mol_predict_and_std(models, x_train, x_test, y_train, y_test):\n",
    "    y_test_avg_predict_dict = {}\n",
    "    std_dict = {}\n",
    "    rmsd_dict = {}\n",
    "    for model in models:\n",
    "        y_test_predicts = []\n",
    "\n",
    "        for i in range(3):\n",
    "            asdf, y_test_predict, ghjk = param_tuning(x_train, x_test, y_train, y_test, model)\n",
    "            # asdf, ghjk ... dummy variables, are not needed here\n",
    "            y_test_predicts.append(y_test_predict)\n",
    "\n",
    "        y_test_predicts_array = np.array(y_test_predicts)\n",
    "\n",
    "        y_test_avg_predict = np.average(y_test_predicts_array, axis=0)\n",
    "        standard_deviation = np.std(y_test_predicts_array, axis=0)\n",
    "        rmsd = np.sqrt(np.average(np.square(y_test_avg_predict-y_test)))\n",
    "        # root-mean-square deviation\n",
    "\n",
    "        y_test_avg_predict_dict[model] = y_test_avg_predict\n",
    "        std_dict[model] = standard_deviation\n",
    "        rmsd_dict[model] = rmsd\n",
    "    return y_test_avg_predict_dict, std_dict, rmsd_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7baac92b-d38c-4e5d-afbf-4f14ab6f144a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
