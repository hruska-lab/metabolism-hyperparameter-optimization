{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c20b59a2-c40a-4a93-8453-2c3b51e77448",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import sys\n",
    "import plotly.subplots as sp\n",
    "import plotly.graph_objects as go\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from project_resources.import_utils import NotebookFinder\n",
    "sys.meta_path.append(NotebookFinder())\n",
    "from project_resources.cytochrome_P450 import fp_from_smiles, parse_jazzy_df, HyperparamTuner, tanimoto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1bf7a3b6-962b-42e5-acab-f4a6f031e15e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_identifiers = [\"linear\", \"KRR\", \"GB\", \"RF\", \"ANN\"]\n",
    "isozymes = [\"3A4\", \"RLM\", \"HLC\"]\n",
    "splitters = [\"rand\", \"scaff\", \"time\"]\n",
    "data_splits = [\"train\", \"test\"]\n",
    "feature_types = [\"morgan\", \"jazzy\"]\n",
    "rel_paths = {\n",
    "    \"morgan_3A4_train_scaff\": r\"project_resources/base_splits/scaffold_splitter/3A4_train.csv\",\n",
    "    \"morgan_3A4_train_rand\": r\"project_resources/base_splits/random/3A4_train.csv\",\n",
    "    \"morgan_3A4_train_time\": r\"project_resources/base_splits/time_split/3A4_train.csv\",\n",
    "    \"morgan_RLM_train_scaff\": r\"project_resources/base_splits/scaffold_splitter/RLM_train.csv\",\n",
    "    \"morgan_RLM_train_rand\": r\"project_resources/base_splits/random/RLM_train.csv\",\n",
    "    \"morgan_RLM_train_time\": r\"project_resources/base_splits/time_split/RLM_train.csv\",\n",
    "    \"morgan_HLC_train_scaff\": r\"project_resources/base_splits/scaffold_splitter/HLC_train.csv\",\n",
    "    \"morgan_HLC_train_rand\": r\"project_resources/base_splits/random/HLC_train.csv\",\n",
    "    \"morgan_HLC_train_time\": r\"project_resources/base_splits/time_split/HLC_train.csv\",\n",
    "\n",
    "    \"morgan_3A4_test_scaff\": r\"project_resources/base_splits/scaffold_splitter/3A4_test.csv\",\n",
    "    \"morgan_3A4_test_rand\": r\"project_resources/base_splits/random/3A4_test.csv\",\n",
    "    \"morgan_3A4_test_time\": r\"project_resources/base_splits/time_split/3A4_test.csv\",\n",
    "    \"morgan_RLM_test_scaff\": r\"project_resources/base_splits/scaffold_splitter/RLM_test.csv\",\n",
    "    \"morgan_RLM_test_rand\": r\"project_resources/base_splits/random/RLM_test.csv\",\n",
    "    \"morgan_RLM_test_time\": r\"project_resources/base_splits/time_split/RLM_test.csv\",\n",
    "    \"morgan_HLC_test_scaff\": r\"project_resources/base_splits/scaffold_splitter/HLC_test.csv\",\n",
    "    \"morgan_HLC_test_rand\": r\"project_resources/base_splits/random/HLC_test.csv\",\n",
    "    \"morgan_HLC_test_time\": r\"project_resources/base_splits/time_split/HLC_test.csv\",\n",
    "\n",
    "    \"jazzy_3A4_train_scaff\": r\"project_resources/jazzy_splits/scaffold_splitter/3A4_train.csv\",\n",
    "    \"jazzy_3A4_train_rand\": r\"project_resources/jazzy_splits/random/3A4_train.csv\",\n",
    "    \"jazzy_3A4_train_time\": r\"project_resources/jazzy_splits/time_split/3A4_train.csv\",\n",
    "    \"jazzy_RLM_train_scaff\": r\"project_resources/jazzy_splits/scaffold_splitter/RLM_train.csv\",\n",
    "    \"jazzy_RLM_train_rand\": r\"project_resources/jazzy_splits/random/RLM_train.csv\",\n",
    "    \"jazzy_RLM_train_time\": r\"project_resources/jazzy_splits/time_split/RLM_train.csv\",\n",
    "    \"jazzy_HLC_train_scaff\": r\"project_resources/jazzy_splits/scaffold_splitter/HLC_train.csv\",\n",
    "    \"jazzy_HLC_train_rand\": r\"project_resources/jazzy_splits/random/HLC_train.csv\",\n",
    "    \"jazzy_HLC_train_time\": r\"project_resources/jazzy_splits/time_split/HLC_train.csv\",\n",
    "\n",
    "    \"jazzy_3A4_test_scaff\": r\"project_resources/jazzy_splits/scaffold_splitter/3A4_test.csv\",\n",
    "    \"jazzy_3A4_test_rand\": r\"project_resources/jazzy_splits/random/3A4_test.csv\",\n",
    "    \"jazzy_3A4_test_time\": r\"project_resources/jazzy_splits/time_split/3A4_test.csv\",\n",
    "    \"jazzy_RLM_test_scaff\": r\"project_resources/jazzy_splits/scaffold_splitter/RLM_test.csv\",\n",
    "    \"jazzy_RLM_test_rand\": r\"project_resources/jazzy_splits/random/RLM_test.csv\",\n",
    "    \"jazzy_RLM_test_time\": r\"project_resources/jazzy_splits/time_split/RLM_test.csv\",\n",
    "    \"jazzy_HLC_test_scaff\": r\"project_resources/jazzy_splits/scaffold_splitter/HLC_test.csv\",\n",
    "    \"jazzy_HLC_test_rand\": r\"project_resources/jazzy_splits/random/HLC_test.csv\",\n",
    "    \"jazzy_HLC_test_time\": r\"project_resources/jazzy_splits/time_split/HLC_test.csv\"\n",
    "}\n",
    "smiles = {}\n",
    "halflives = {}\n",
    "models = {}\n",
    "mol_features = {}\n",
    "best_model_hyperparams = {}\n",
    "tanimoto_sims = {}\n",
    "fingerprints = {}\n",
    "y_predicted = {}\n",
    "rmsds = {}\n",
    "stds = {}\n",
    "best_models = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "45e6a38a-c133-4b63-b662-e7d272bf6a0c",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'project_resources/optuna/morgan/random/RLM/RF.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_19336\\2993472745.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     18\u001b[0m             \u001b[0mbest_model_hyperparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0m_type\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msplitter\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0misozyme\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mmodel_id\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmodel_identifiers\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m                 \u001b[0mjl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mjoblib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"project_resources/optuna/{_type}/{splitter_name}/{isozyme}/{model_id}.pkl\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m                 \u001b[0mmodels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0m_type\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msplitter\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0misozyme\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmodel_id\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mjl\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m                 \u001b[0mbest_model_hyperparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0m_type\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msplitter\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0misozyme\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmodel_id\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mjl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_trial\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\soc\\lib\\site-packages\\joblib\\numpy_pickle.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(filename, mmap_mode)\u001b[0m\n\u001b[0;32m    648\u001b[0m             \u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_unpickle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    649\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 650\u001b[1;33m         \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    651\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0m_read_fileobject\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmmap_mode\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfobj\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    652\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'project_resources/optuna/morgan/random/RLM/RF.pkl'"
     ]
    }
   ],
   "source": [
    "# load all models from optuna\n",
    "# and get the hyperparameters of the best model from each study\n",
    "# doesn't get the user_attrs={'fit_intercept': True} from linear, need to get manually\n",
    "for _type in feature_types:\n",
    "    models[_type] = {}\n",
    "    best_model_hyperparams[_type] = {}\n",
    "    for splitter in splitters:\n",
    "        models[_type][splitter] = {}\n",
    "        best_model_hyperparams[_type][splitter] = {}\n",
    "        if splitter == \"rand\":\n",
    "            splitter_name = \"random\"\n",
    "        elif splitter == \"scaff\":\n",
    "            splitter_name = \"scaffold_splitter\"\n",
    "        else:\n",
    "            splitter_name = \"time_split\"\n",
    "        for isozyme in isozymes:\n",
    "            models[_type][splitter][isozyme] = {}\n",
    "            best_model_hyperparams[_type][splitter][isozyme] = {}\n",
    "            for model_id in model_identifiers:\n",
    "                jl = joblib.load(f\"project_resources/optuna/{_type}/{splitter_name}/{isozyme}/{model_id}.pkl\")\n",
    "                models[_type][splitter][isozyme][model_id] = jl\n",
    "                best_model_hyperparams[_type][splitter][isozyme][model_id] = jl.best_trial.params\n",
    "print(models[\"morgan\"][\"rand\"][\"3A4\"][\"linear\"].best_trial)\n",
    "print(best_model_hyperparams[\"morgan\"][\"rand\"][\"3A4\"][\"linear\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44efc7bf-5892-4374-acca-37fa02179dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_id in model_identifiers:\n",
    "    print(best_model_hyperparams[\"morgan\"][\"rand\"][\"3A4\"][model_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d30a7a-0017-4e64-af76-26882c83e15e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load smiles used for ML with Morgan features\n",
    "smiles[\"morgan\"] = {}\n",
    "halflives[\"morgan\"] = {}\n",
    "for splitter in splitters:\n",
    "    smiles[\"morgan\"][splitter] = {}\n",
    "    halflives[\"morgan\"][splitter] = {}\n",
    "    for isozyme in isozymes:\n",
    "        smiles[\"morgan\"][splitter][isozyme] = {}\n",
    "        halflives[\"morgan\"][splitter][isozyme] = {}\n",
    "        for split in data_splits:\n",
    "            df = pd.read_csv(rel_paths[f\"morgan_{isozyme}_{split}_{splitter}\"])\n",
    "            df_smiles = list(df[\"smiles\"])\n",
    "            df_halflives = list(df[\"half-life\"])\n",
    "            smiles[\"morgan\"][splitter][isozyme][split] = df_smiles\n",
    "            halflives[\"morgan\"][splitter][isozyme][split] = df_halflives\n",
    "print(\"successfully loaded smiles for Morgan fingerprints\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95ac9307-86da-4cc4-9594-cc4b75e2f2df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load Jazzy features from csv files and their corresponding smiles\n",
    "smiles[\"jazzy\"] = {}\n",
    "halflives[\"jazzy\"] = {}\n",
    "for splitter in splitters:\n",
    "    mol_features[splitter] = {}\n",
    "    smiles[\"jazzy\"][splitter] = {}\n",
    "    halflives[\"jazzy\"][splitter] = {}\n",
    "    for isozyme in isozymes:\n",
    "        mol_features[splitter][isozyme] = {}\n",
    "        smiles[\"jazzy\"][splitter][isozyme] = {}\n",
    "        halflives[\"jazzy\"][splitter][isozyme] = {}\n",
    "        for split in data_splits:\n",
    "            df = pd.read_csv(rel_paths[f\"jazzy_{isozyme}_{split}_{splitter}\"])\n",
    "            jazzy_smiles, features, thalfs, contains_nan = parse_jazzy_df(df)\n",
    "            smiles[\"jazzy\"][splitter][isozyme][split] = jazzy_smiles\n",
    "            mol_features[splitter][isozyme][split] = features\n",
    "            halflives[\"jazzy\"][splitter][isozyme][split] = thalfs\n",
    "print(\"successfully loaded Jazzy features and their smiles\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac72393e-c232-409f-8cde-f307967ac25a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# smiles to Morgan fingerprint\n",
    "for _type in feature_types:\n",
    "    fingerprints[_type] = {}  # need to destinguish between Jazzy and Morngan since Jazzy ommits some mols\n",
    "    for splitter in splitters:\n",
    "        fingerprints[_type][splitter] = {}\n",
    "        for isozyme in isozymes:\n",
    "            fingerprints[_type][splitter][isozyme] = {}\n",
    "            for data_split in data_splits:\n",
    "                fps = fp_from_smiles(smiles[_type][splitter][isozyme][data_split])\n",
    "                fingerprints[_type][splitter][isozyme][data_split] = np.array(fps)\n",
    "print(\"successfully generated Morgan fingerprints\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e2f2b95-c425-4549-84da-381e298b8615",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# test models with the best hyperparams\n",
    "for _type in feature_types:\n",
    "    y_predicted[_type] = {}\n",
    "    rmsds[_type] = {}\n",
    "    stds[_type] = {}\n",
    "    best_models[_type] = {}\n",
    "    for splitter in splitters:\n",
    "        y_predicted[_type][splitter] = {}\n",
    "        rmsds[_type][splitter] = {}\n",
    "        stds[_type][splitter] = {}\n",
    "        best_models[_type][splitter] = {}\n",
    "        for isozyme in isozymes:\n",
    "            y_predicted[_type][splitter][isozyme] = {}\n",
    "            rmsds[_type][splitter][isozyme] = {}\n",
    "            stds[_type][splitter][isozyme] = {}\n",
    "            group_rmsds = {}\n",
    "            print(_type, splitter, isozyme)\n",
    "            for model_id in model_identifiers:\n",
    "                hyperparams = best_model_hyperparams[_type][splitter][isozyme][model_id]\n",
    "                if _type == \"morgan\":\n",
    "                    X_train = fingerprints[\"morgan\"][splitter][isozyme][\"train\"]\n",
    "                    X_test = fingerprints[\"morgan\"][splitter][isozyme][\"test\"]\n",
    "                else:\n",
    "                    X_train = mol_features[splitter][isozyme][\"train\"]\n",
    "                    X_test = mol_features[splitter][isozyme][\"test\"]\n",
    "                y_train = np.array(halflives[_type][splitter][isozyme][\"train\"])\n",
    "                y_test = np.array(halflives[_type][splitter][isozyme][\"test\"])\n",
    "\n",
    "                if model_id == 'linear':\n",
    "                    alpha = hyperparams[\"alpha\"]\n",
    "                    l1_ratio = hyperparams[\"l1_ratio\"]\n",
    "                    reg = ElasticNet(alpha=alpha, l1_ratio=l1_ratio, fit_intercept=True)\n",
    "\n",
    "                if model_id == 'KRR':\n",
    "                    alpha = hyperparams[\"alpha\"]\n",
    "                    gamma = hyperparams[\"gamma\"]\n",
    "                    kernel = hyperparams[\"kernel\"]\n",
    "                    reg = KernelRidge(alpha=alpha, gamma=gamma, kernel=kernel)\n",
    "\n",
    "                if model_id == 'GB':\n",
    "                    n_estimators = hyperparams[\"n_estimators\"]\n",
    "                    learning_rate = hyperparams[\"learning_rate\"]\n",
    "                    max_depth = hyperparams[\"max_depth\"]\n",
    "                    reg = GradientBoostingRegressor(n_estimators=n_estimators, learning_rate=learning_rate, max_depth=max_depth)\n",
    "\n",
    "                if model_id == 'RF':\n",
    "                    n_estimators = hyperparams[\"n_estimators\"]\n",
    "                    max_features = hyperparams[\"max_features\"]\n",
    "                    max_depth = hyperparams[\"max_depth\"]\n",
    "                    reg = RandomForestRegressor(n_estimators=n_estimators, max_features=max_features, max_depth=max_depth)\n",
    "\n",
    "                if model_id == 'ANN':\n",
    "                    learning_rate_init = hyperparams[\"learning_rate_init\"]\n",
    "                    hidden_layer_sizes = hyperparams[\"hidden_layer_sizes\"]\n",
    "                    reg = MLPRegressor(learning_rate_init=learning_rate_init, hidden_layer_sizes=hidden_layer_sizes)\n",
    "\n",
    "                # create an instance of HyperparamTuner without specifying any model_identifier\n",
    "                tuner = HyperparamTuner(\"foo\", X_train, y_train, X_test, y_test)\n",
    "                # and use the train_test_return function with return_predictions to get the rmsd values\n",
    "                # average over multiple runs of the same model\n",
    "                runs_rmsds = []\n",
    "                runs_y_test_predictions = []\n",
    "                runs_stds = []\n",
    "                for i in range(10):\n",
    "                    rmsd, y_test_predictions, std = tuner.train_test_return(\"foo\", reg, return_predictions=True)\n",
    "                    runs_rmsds.append(rmsd)\n",
    "                    runs_y_test_predictions.append(y_test_predictions)\n",
    "                    runs_stds.append(std)\n",
    "                mean_rmsd = np.mean(runs_rmsds, axis=0)\n",
    "                mean_y_test_predictions = np.mean(runs_y_test_predictions, axis=0)\n",
    "                mean_stds = np.mean(runs_stds, axis=0)\n",
    "                group_rmsds[mean_rmsd] = model_id\n",
    "                rmsds[_type][model_id] = mean_rmsd\n",
    "                y_predicted[_type][model_id] = mean_y_test_predictions\n",
    "                stds[_type][model_id] = mean_stds\n",
    "                print(mean_rmsd, f\"y_test predictions: {y_test_predictions[:5]}, {len(y_test_predictions)}\")\n",
    "                print(f\"     standard deviations: {mean_stds[:4]}, {len(mean_stds)}\")\n",
    "\n",
    "            # find best model for each dataset and its rmsd\n",
    "            min_rmsd = min(group_rmsds.keys())\n",
    "            best_model = group_rmsds[min_rmsd]\n",
    "            best_models[_type] = (best_model, min_rmsd)\n",
    "            print(f\"best was {best_model} with rmsd {min_rmsd}\")\n",
    "\n",
    "            print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eae5ac8-d3ac-4f7b-af60-1af72a89c51c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for _type in feature_types:\n",
    "    tanimoto_sims[_type] = {}\n",
    "    for splitter in splitters:\n",
    "        print(splitter)\n",
    "        tanimoto_sims[_type][splitter] = {}\n",
    "        for isozyme in isozymes:\n",
    "            tanimoto_similarities = tanimoto(fingerprints[_type][splitter][isozyme][\"test\"], fingerprints[_type][splitter][isozyme][\"train\"])\n",
    "            tanimoto_sims[_type][splitter][isozyme] = tanimoto_similarities\n",
    "            median = np.median(tanimoto_similarities)\n",
    "            mean = np.mean(tanimoto_similarities)\n",
    "            print(f\"length: {len(tanimoto_similarities)}, median: {median}, arithmetic mean: {mean}, \",\n",
    "                  tanimoto_sims[_type][splitter][isozyme][:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f2daec-2db2-4747-b3cf-c0294a2846a2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a 20x3 grid of subplots\n",
    "fig, axs = plt.subplots(6, 3, figsize=(20, 30))\n",
    "\n",
    "plot_counter = 0\n",
    "# Loop through each subplot and plot different data\n",
    "for _type in feature_types:\n",
    "    for splitter in splitters:\n",
    "        for isozyme in isozymes:\n",
    "            model_id = best_models[_type][splitter][isozyme][0]\n",
    "            plot_x = tanimoto_sims[_type][splitter][isozyme]\n",
    "            plot_y = y_predicted[_type][splitter][isozyme][model_id]\n",
    "\n",
    "            # Get the current axis based on the plot counter\n",
    "            ax = axs[plot_counter // 3, plot_counter % 3]\n",
    "\n",
    "            # Plot the data and customize the subplot\n",
    "            ax.scatter(plot_x, plot_y)\n",
    "            ax.set_title(f'{_type}, {splitter}, {isozyme}, {model_id}')\n",
    "            ax.set(xlabel='tanimoto similarity', ylabel='prediction error')\n",
    "\n",
    "            plot_counter += 1\n",
    "\n",
    "plt.tight_layout()  # Ensure the subplots are properly laid out\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc21afce-f634-490f-8c7b-cebe1fa43371",
   "metadata": {},
   "outputs": [],
   "source": [
    "_type = \"morgan\"\n",
    "subplot_titles = []\n",
    "# generate plot titles\n",
    "for splitter in splitters:\n",
    "    for isozyme in isozymes:\n",
    "        model_id = best_models[_type][splitter][isozyme][0]\n",
    "        title = f'{_type}, {splitter}, {isozyme}, {model_id}'\n",
    "        subplot_titles.append(title)\n",
    "\n",
    "# Create a 20x3 grid of subplots\n",
    "fig = sp.make_subplots(rows=3, cols=3, subplot_titles=subplot_titles)\n",
    "\n",
    "plot_counter = 0\n",
    "# Loop through each subplot and plot different data\n",
    "\n",
    "for splitter in splitters:\n",
    "    for isozyme in isozymes:\n",
    "        model_id = best_models[_type][splitter][isozyme][0]\n",
    "        plot_x = halflives[_type][splitter][isozyme][\"test\"]\n",
    "        plot_y = y_predicted[_type][splitter][isozyme][model_id]\n",
    "        std = stds[_type][splitter][isozyme][model_id]\n",
    "\n",
    "        # Plot the data\n",
    "        scatter_trace = go.Scatter(\n",
    "            x=plot_x,\n",
    "            y=plot_y,\n",
    "            mode='markers',\n",
    "            error_y=dict(type='data', array=std, visible=True),\n",
    "            name=f'{_type}, {splitter}, {isozyme}, {model_id}'\n",
    "        )\n",
    "\n",
    "        # Add the diagonal line\n",
    "        diagonal_trace = go.Scatter(\n",
    "            x=plot_x,\n",
    "            y=plot_x,\n",
    "            mode='lines',\n",
    "            line=dict(color='orange', dash='dash'),\n",
    "            showlegend=False\n",
    "        )\n",
    "\n",
    "        # Add the traces to the subplot\n",
    "        fig.add_trace(scatter_trace, row=plot_counter // 3 + 1, col=plot_counter % 3 + 1)\n",
    "        fig.add_trace(diagonal_trace, row=plot_counter // 3 + 1, col=plot_counter % 3 + 1)\n",
    "\n",
    "        # Customize the subplot\n",
    "        fig.update_xaxes(title_text='real natural log half-life', row=plot_counter // 3 + 1, col=plot_counter % 3 + 1)\n",
    "        fig.update_yaxes(title_text='predicted natural log half-life', row=plot_counter // 3 + 1, col=plot_counter % 3 + 1)\n",
    "\n",
    "        plot_counter += 1\n",
    "\n",
    "# Update layout\n",
    "fig.update_layout(height=1500, title_text=\"Subplots with Plotly\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b1172b-05fa-42ba-9e71-b7ab41e9d7a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "_type = \"jazzy\"\n",
    "subplot_titles = []\n",
    "# generate plot titles\n",
    "for splitter in splitters:\n",
    "    for isozyme in isozymes:\n",
    "        model_id = best_models[_type][splitter][isozyme][0]\n",
    "        title = f'{_type}, {splitter}, {isozyme}, {model_id}'\n",
    "        subplot_titles.append(title)\n",
    "\n",
    "# Create a 20x3 grid of subplots\n",
    "fig = sp.make_subplots(rows=3, cols=3, subplot_titles=subplot_titles)\n",
    "\n",
    "plot_counter = 0\n",
    "# Loop through each subplot and plot different data\n",
    "\n",
    "for splitter in splitters:\n",
    "    for isozyme in isozymes:\n",
    "        model_id = best_models[_type][splitter][isozyme][0]\n",
    "        plot_x = halflives[_type][splitter][isozyme][\"test\"]\n",
    "        plot_y = y_predicted[_type][splitter][isozyme][model_id]\n",
    "        std = stds[_type][splitter][isozyme][model_id]\n",
    "\n",
    "        # Plot the data\n",
    "        scatter_trace = go.Scatter(\n",
    "            x=plot_x,\n",
    "            y=plot_y,\n",
    "            mode='markers',\n",
    "            error_y=dict(type='data', array=std, visible=True),\n",
    "            name=f'{_type}, {splitter}, {isozyme}, {model_id}'\n",
    "        )\n",
    "\n",
    "        # Add the diagonal line\n",
    "        diagonal_trace = go.Scatter(\n",
    "            x=plot_x,\n",
    "            y=plot_x,\n",
    "            mode='lines',\n",
    "            line=dict(color='orange', dash='dash'),\n",
    "            showlegend=False\n",
    "        )\n",
    "\n",
    "        # Add the traces to the subplot\n",
    "        fig.add_trace(scatter_trace, row=plot_counter // 3 + 1, col=plot_counter % 3 + 1)\n",
    "        fig.add_trace(diagonal_trace, row=plot_counter // 3 + 1, col=plot_counter % 3 + 1)\n",
    "\n",
    "        # Customize the subplot\n",
    "        fig.update_xaxes(title_text='real natural log half-life', row=plot_counter // 3 + 1, col=plot_counter % 3 + 1)\n",
    "        fig.update_yaxes(title_text='predicted natural log half-life', row=plot_counter // 3 + 1, col=plot_counter % 3 + 1)\n",
    "\n",
    "        plot_counter += 1\n",
    "\n",
    "# Update layout\n",
    "fig.update_layout(height=1500, title_text=\"Subplots with Plotly\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58693735-0edd-4468-aa6b-45fbfefa9a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "for _type in feature_types:\n",
    "    bar_width = 0.25\n",
    "\n",
    "    r1 = np.arange(len(splitters))\n",
    "    r2 = [x + bar_width for x in r1]\n",
    "    r3 = [x + bar_width for x in r2]\n",
    "\n",
    "    grouped_rmsds = {}\n",
    "    for splitter in splitters:\n",
    "        grouped_rmsds[splitter] = []\n",
    "        for isozyme in isozymes:\n",
    "            grouped_rmsds[splitter].append(best_models[_type][splitter][isozyme][1])\n",
    "\n",
    "    plt.bar(r1, grouped_rmsds[\"rand\"], width=bar_width, label='Bar 1')\n",
    "    plt.bar(r2, grouped_rmsds[\"scaff\"], width=bar_width, label='Bar 2')\n",
    "    plt.bar(r3, grouped_rmsds[\"time\"], width=bar_width, label='Bar 3')\n",
    "\n",
    "    plt.xlabel('splitters')\n",
    "    plt.ylabel('rmsd')\n",
    "    plt.title(f'{_type} root mean square deviations')\n",
    "    plt.xticks([r + bar_width for r in range(len(splitters))], [\"random\", \"scaffold\", \"publication date\"])\n",
    "    plt.legend(isozymes)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b93f0f59-84b4-4fee-a5c1-b1b55f60b661",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
