{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c20b59a2-c40a-4a93-8453-2c3b51e77448",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from C:\\Users\\Lukas\\Documents\\datacytochromy\\project_resources\\cytochrome_P450.ipynb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lukas\\anaconda3\\envs\\it4i\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import sys\n",
    "import plotly.subplots as sp\n",
    "import plotly.graph_objects as go\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from project_resources.import_utils import NotebookFinder\n",
    "sys.meta_path.append(NotebookFinder())\n",
    "from project_resources.cytochrome_P450 import fp_from_smiles, parse_jazzy_df, HyperparamTuner, tanimoto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1bf7a3b6-962b-42e5-acab-f4a6f031e15e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_identifiers = [\"linear\", \"KRR\", \"GB\", \"RF\", \"ANN\"]\n",
    "isozymes = [\"3A4\", \"RLM\", \"HLC\"]\n",
    "splitters = [\"rand\", \"scaff\", \"time\"]\n",
    "data_splits = [\"train\", \"test\"]\n",
    "feature_types = [\"morgan\", \"jazzy\"]\n",
    "rel_paths = {\n",
    "    \"morgan_3A4_train_scaff\": r\"project_resources/base_splits/scaffold_splitter/3A4_train.csv\",\n",
    "    \"morgan_3A4_train_rand\": r\"project_resources/base_splits/random/3A4_train.csv\",\n",
    "    \"morgan_3A4_train_time\": r\"project_resources/base_splits/time_split/3A4_train.csv\",\n",
    "    \"morgan_RLM_train_scaff\": r\"project_resources/base_splits/scaffold_splitter/RLM_train.csv\",\n",
    "    \"morgan_RLM_train_rand\": r\"project_resources/base_splits/random/RLM_train.csv\",\n",
    "    \"morgan_RLM_train_time\": r\"project_resources/base_splits/time_split/RLM_train.csv\",\n",
    "    \"morgan_HLC_train_scaff\": r\"project_resources/base_splits/scaffold_splitter/HLC_train.csv\",\n",
    "    \"morgan_HLC_train_rand\": r\"project_resources/base_splits/random/HLC_train.csv\",\n",
    "    \"morgan_HLC_train_time\": r\"project_resources/base_splits/time_split/HLC_train.csv\",\n",
    "\n",
    "    \"morgan_3A4_test_scaff\": r\"project_resources/base_splits/scaffold_splitter/3A4_test.csv\",\n",
    "    \"morgan_3A4_test_rand\": r\"project_resources/base_splits/random/3A4_test.csv\",\n",
    "    \"morgan_3A4_test_time\": r\"project_resources/base_splits/time_split/3A4_test.csv\",\n",
    "    \"morgan_RLM_test_scaff\": r\"project_resources/base_splits/scaffold_splitter/RLM_test.csv\",\n",
    "    \"morgan_RLM_test_rand\": r\"project_resources/base_splits/random/RLM_test.csv\",\n",
    "    \"morgan_RLM_test_time\": r\"project_resources/base_splits/time_split/RLM_test.csv\",\n",
    "    \"morgan_HLC_test_scaff\": r\"project_resources/base_splits/scaffold_splitter/HLC_test.csv\",\n",
    "    \"morgan_HLC_test_rand\": r\"project_resources/base_splits/random/HLC_test.csv\",\n",
    "    \"morgan_HLC_test_time\": r\"project_resources/base_splits/time_split/HLC_test.csv\",\n",
    "\n",
    "    \"jazzy_3A4_train_scaff\": r\"project_resources/jazzy_splits/scaffold_splitter/3A4_train.csv\",\n",
    "    \"jazzy_3A4_train_rand\": r\"project_resources/jazzy_splits/random/3A4_train.csv\",\n",
    "    \"jazzy_3A4_train_time\": r\"project_resources/jazzy_splits/time_split/3A4_train.csv\",\n",
    "    \"jazzy_RLM_train_scaff\": r\"project_resources/jazzy_splits/scaffold_splitter/RLM_train.csv\",\n",
    "    \"jazzy_RLM_train_rand\": r\"project_resources/jazzy_splits/random/RLM_train.csv\",\n",
    "    \"jazzy_RLM_train_time\": r\"project_resources/jazzy_splits/time_split/RLM_train.csv\",\n",
    "    \"jazzy_HLC_train_scaff\": r\"project_resources/jazzy_splits/scaffold_splitter/HLC_train.csv\",\n",
    "    \"jazzy_HLC_train_rand\": r\"project_resources/jazzy_splits/random/HLC_train.csv\",\n",
    "    \"jazzy_HLC_train_time\": r\"project_resources/jazzy_splits/time_split/HLC_train.csv\",\n",
    "\n",
    "    \"jazzy_3A4_test_scaff\": r\"project_resources/jazzy_splits/scaffold_splitter/3A4_test.csv\",\n",
    "    \"jazzy_3A4_test_rand\": r\"project_resources/jazzy_splits/random/3A4_test.csv\",\n",
    "    \"jazzy_3A4_test_time\": r\"project_resources/jazzy_splits/time_split/3A4_test.csv\",\n",
    "    \"jazzy_RLM_test_scaff\": r\"project_resources/jazzy_splits/scaffold_splitter/RLM_test.csv\",\n",
    "    \"jazzy_RLM_test_rand\": r\"project_resources/jazzy_splits/random/RLM_test.csv\",\n",
    "    \"jazzy_RLM_test_time\": r\"project_resources/jazzy_splits/time_split/RLM_test.csv\",\n",
    "    \"jazzy_HLC_test_scaff\": r\"project_resources/jazzy_splits/scaffold_splitter/HLC_test.csv\",\n",
    "    \"jazzy_HLC_test_rand\": r\"project_resources/jazzy_splits/random/HLC_test.csv\",\n",
    "    \"jazzy_HLC_test_time\": r\"project_resources/jazzy_splits/time_split/HLC_test.csv\"\n",
    "}\n",
    "smiles = {}\n",
    "halflives = {}\n",
    "models = {}\n",
    "mol_features = {}\n",
    "best_model_hyperparams = {}\n",
    "tanimoto_sims = {}\n",
    "fingerprints = {}\n",
    "y_predicted = {}\n",
    "rmsds = {}\n",
    "stds = {}\n",
    "best_models = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "45e6a38a-c133-4b63-b662-e7d272bf6a0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FrozenTrial(number=10, state=1, values=[0.2072958440522067], datetime_start=datetime.datetime(2023, 11, 7, 17, 34, 20, 5131), datetime_complete=datetime.datetime(2023, 11, 7, 17, 34, 20, 44156), params={'alpha': 0.06264656704193015, 'l1_ratio': 0.6627785878364576}, user_attrs={'fit_intercept': True}, system_attrs={}, intermediate_values={}, distributions={'alpha': FloatDistribution(high=0.1, log=False, low=1e-05, step=None), 'l1_ratio': FloatDistribution(high=1.0, log=False, low=0.0, step=None)}, trial_id=10, value=None)\n",
      "{'alpha': 0.06264656704193015, 'l1_ratio': 0.6627785878364576}\n"
     ]
    }
   ],
   "source": [
    "# load all models from optuna\n",
    "# and get the hyperparameters of the best model from each study\n",
    "# doesn't get the user_attrs={'fit_intercept': True} from linear, need to get manually\n",
    "for _type in feature_types:\n",
    "    models[_type] = {}\n",
    "    best_model_hyperparams[_type] = {}\n",
    "    for splitter in splitters:\n",
    "        models[_type][splitter] = {}\n",
    "        best_model_hyperparams[_type][splitter] = {}\n",
    "        if splitter == \"rand\":\n",
    "            splitter_name = \"random\"\n",
    "        elif splitter == \"scaff\":\n",
    "            splitter_name = \"scaffold_splitter\"\n",
    "        else:\n",
    "            splitter_name = \"time_split\"\n",
    "        for isozyme in isozymes:\n",
    "            models[_type][splitter][isozyme] = {}\n",
    "            best_model_hyperparams[_type][splitter][isozyme] = {}\n",
    "            for model_id in model_identifiers:\n",
    "                jl = joblib.load(f\"project_resources/optuna/{_type}/{splitter_name}/{isozyme}/{model_id}.pkl\")\n",
    "                models[_type][splitter][isozyme][model_id] = jl\n",
    "                best_model_hyperparams[_type][splitter][isozyme][model_id] = jl.best_trial.params\n",
    "print(models[\"morgan\"][\"rand\"][\"3A4\"][\"linear\"].best_trial)\n",
    "print(best_model_hyperparams[\"morgan\"][\"rand\"][\"3A4\"][\"linear\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "44efc7bf-5892-4374-acca-37fa02179dc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 0.06264656704193015, 'l1_ratio': 0.6627785878364576}\n",
      "{'alpha': 0.1987948012473062, 'gamma': 6.4494268671110156e-15, 'kernel': 'linear'}\n",
      "{'n_estimators': 200, 'learning_rate': 0.26450725867019154, 'max_depth': 3}\n",
      "{'n_estimators': 50, 'max_features': 'sqrt', 'max_depth': 10}\n",
      "{'learning_rate_init': 0.02137541820323554, 'hidden_layer_sizes': [20, 20]}\n"
     ]
    }
   ],
   "source": [
    "for model_id in model_identifiers:\n",
    "    print(best_model_hyperparams[\"morgan\"][\"rand\"][\"3A4\"][model_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "09d30a7a-0017-4e64-af76-26882c83e15e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully loaded smiles for Morgan fingerprints\n"
     ]
    }
   ],
   "source": [
    "# load smiles used for ML with Morgan features\n",
    "smiles[\"morgan\"] = {}\n",
    "halflives[\"morgan\"] = {}\n",
    "for splitter in splitters:\n",
    "    smiles[\"morgan\"][splitter] = {}\n",
    "    halflives[\"morgan\"][splitter] = {}\n",
    "    for isozyme in isozymes:\n",
    "        smiles[\"morgan\"][splitter][isozyme] = {}\n",
    "        halflives[\"morgan\"][splitter][isozyme] = {}\n",
    "        for split in data_splits:\n",
    "            df = pd.read_csv(rel_paths[f\"morgan_{isozyme}_{split}_{splitter}\"])\n",
    "            df_smiles = list(df[\"smiles\"])\n",
    "            df_halflives = list(df[\"half-life\"])\n",
    "            smiles[\"morgan\"][splitter][isozyme][split] = df_smiles\n",
    "            halflives[\"morgan\"][splitter][isozyme][split] = df_halflives\n",
    "print(\"successfully loaded smiles for Morgan fingerprints\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "95ac9307-86da-4cc4-9594-cc4b75e2f2df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     56, [63, 'CC(C)(O)c1cc(F)c2c(c1)C(=O)N(Cc1ccc(Cl)cn1)[C@@]2(OCC1(O)CC1)c1ccc(Cl)cc1', 0.9999999999999998, 13.1753, 1.4177, 11.3044, -7.3559, -125.8906, -119.4889]\n",
      "     14, [23, 'Cc1ncsc1-c1ccc([C@H](CC(=O)NCCCCCCNC(=O)COc2c(-c3csc(N4CCOCC4)n3)ccc(F)c2F)NC(=O)[C@@H]2C[C@@H](O)CN2C(=O)[C@@H](NC(=O)C2(F)CC2)C(C)(C)C)cc1', 0.0622624201077031, 28.4327, 3.274, 23.4872, -4.0348, -286.1545, -257.0326]\n",
      "     removed index 325 corresponding to NaN\n",
      "     removed index 678 corresponding to NaN\n",
      "     removed index 725 corresponding to NaN\n",
      "     removed index 1053 corresponding to NaN\n",
      "     1417, [439, 'CN1C(=O)c2ccccc2[S@+]([O-])c2ccc(C(=O)NCc3ccc(Br)cc3)cc21', 0.4181064270905321, 10.3104, 0.7256, 7.5559, -14.2816, -86.2027, -96.3091]\n",
      "     356, [66, 'CC(=O)c1c(C)[nH]c(C(=O)Nc2cccc([S+](=O)([O-])Nc3cccc(C#N)c3)c2)c1C', 0.8327574291637871, 10.4683, 2.4345, 9.1374, -15.7732, -116.2014, -124.8128]\n",
      "     151, [36, 'N#Cc1ccc(CN2CCC(N3CCNC3=O)CC2)cc1', 0.7615658362989324, 8.7086, 0.7824, 4.7992, -7.9813, -74.8159, -75.7409]\n",
      "     38, [185, 'c1ccc(Nc2ncc(-c3cncnc3)c3c2OCC3)cc1', 1.0, 7.6502, 0.7908, 4.359, -17.5939, -69.2221, -78.0498]\n",
      "     56, [30, 'COc1cccc([C@@H](CO)NC(=O)[C@@H](C)N2Cc3ccc(-c4nc(NC5CCOCC5)ncc4Cl)cc3C2=O)c1', 0.0147310164129507, 16.2478, 2.1011, 12.7179, -10.0882, -164.348, -156.2467]\n",
      "     14, [29, 'O=C1CCC(N2C(=O)c3cccc(NCCOCCOCCNC(=O)c4ccc5c(c4)nc(Nc4cccc(Cl)c4)c4ccncc45)c3C2=O)C(=O)N1', 0.0400167292931223, 18.7621, 3.2764, 15.83, -24.805, -206.8013, -216.3639]\n",
      "     removed index 627 corresponding to NaN\n",
      "     removed index 628 corresponding to NaN\n",
      "     removed index 1065 corresponding to NaN\n",
      "     removed index 1109 corresponding to NaN\n",
      "     1417, [41, 'CNC(=O)C1CCN(c2nc(-c3ccc(Br)cc3)cs2)CC1', 0.8728403593642018, 8.8766, 0.5795, 5.4967, -5.3755, -74.4969, -72.179]\n",
      "     356, [675, 'O=c1cc(CN2CCCN(c3ccc(C(F)(F)F)cn3)CC2)nc2ccccn12', 0.2695231513476157, 11.6693, 0.0, 8.7277, -7.9637, -109.4358, -87.089]\n",
      "     151, [9, 'Cc1cc(F)ccc1OC1CN(Cc2ccc(C#N)cc2)C1', 0.2473309608540924, 8.9224, 0.0, 4.8259, -11.1508, -61.3626, -68.7406]\n",
      "     38, [20, 'Fc1cccc(-c2cnc([C@@H]3COCCN3Cc3cnc[nH]3)[nH]2)c1', 0.4599644128113878, 8.6917, 1.4354, 6.9778, -10.2452, -97.3783, -101.0987]\n",
      "     56, [25, 'O=C(NC1CCN(CCc2c[nH]c3ccccc23)CC1)c1ccccc1', 0.0439188969472542, 9.3803, 1.1336, 4.4019, -10.2484, -68.9045, -79.1529]\n",
      "     14, [44, 'COc1cc(F)cc([C@@H](CO)NC(=O)[C@@H](C)N2Cc3ccc(-c4nc(NC5COC5)ncc4Cl)cc3C2=O)c1', 0.1384047171537122, 15.1005, 2.4247, 13.7023, -11.5729, -168.823, -163.9418]\n",
      "     removed index 1085 corresponding to NaN\n",
      "     1420, [865, 'O=c1c(O)c(-c2ccc(O)cc2)oc2cc(O)cc(O)c12', 0.1807187284035936, 4.8109, 4.2098, 9.0356, -15.906, -100.4349, -116.3409]\n",
      "     removed index 149 corresponding to NaN\n",
      "     removed index 152 corresponding to NaN\n",
      "     removed index 165 corresponding to NaN\n",
      "     353, [963, 'COc1cc(C(=O)Nc2nc(-c3ccccc3)cs2)ccc1NS(=O)(=O)c1ccc(C)cc1', 0.1485832757429163, 10.6471, 1.8191, 7.4917, -18.2286, -98.1729, -109.0432]\n",
      "     151, [107, 'O=C(Nc1cnc(-c2ccccc2)nc1)c1ccccc1', 1.0, 7.4704, 0.6471, 3.9158, -15.3358, -60.546, -70.5429]\n",
      "     38, [104, 'Cc1ccccc1-c1[nH]nc2ncc(-c3ccccc3)nc12', 0.7215302491103203, 6.5793, 0.7599, 2.616, -18.8676, -48.3099, -58.8456]\n",
      "successfully loaded Jazzy features and their smiles\n"
     ]
    }
   ],
   "source": [
    "# load Jazzy features from csv files and their corresponding smiles\n",
    "smiles[\"jazzy\"] = {}\n",
    "halflives[\"jazzy\"] = {}\n",
    "for splitter in splitters:\n",
    "    mol_features[splitter] = {}\n",
    "    smiles[\"jazzy\"][splitter] = {}\n",
    "    halflives[\"jazzy\"][splitter] = {}\n",
    "    for isozyme in isozymes:\n",
    "        mol_features[splitter][isozyme] = {}\n",
    "        smiles[\"jazzy\"][splitter][isozyme] = {}\n",
    "        halflives[\"jazzy\"][splitter][isozyme] = {}\n",
    "        for split in data_splits:\n",
    "            df = pd.read_csv(rel_paths[f\"jazzy_{isozyme}_{split}_{splitter}\"])\n",
    "            jazzy_smiles, features, thalfs, contains_nan = parse_jazzy_df(df)\n",
    "            smiles[\"jazzy\"][splitter][isozyme][split] = jazzy_smiles\n",
    "            mol_features[splitter][isozyme][split] = features\n",
    "            halflives[\"jazzy\"][splitter][isozyme][split] = thalfs\n",
    "print(\"successfully loaded Jazzy features and their smiles\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ac72393e-c232-409f-8cde-f307967ac25a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully generated Morgan fingerprints\n"
     ]
    }
   ],
   "source": [
    "# smiles to Morgan fingerprint\n",
    "for _type in feature_types:\n",
    "    fingerprints[_type] = {}  # need to destinguish between Jazzy and Morngan since Jazzy ommits some mols\n",
    "    for splitter in splitters:\n",
    "        fingerprints[_type][splitter] = {}\n",
    "        for isozyme in isozymes:\n",
    "            fingerprints[_type][splitter][isozyme] = {}\n",
    "            for data_split in data_splits:\n",
    "                fps = fp_from_smiles(smiles[_type][splitter][isozyme][data_split])\n",
    "                fingerprints[_type][splitter][isozyme][data_split] = np.array(fps)\n",
    "print(\"successfully generated Morgan fingerprints\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5e2f2b95-c425-4549-84da-381e298b8615",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "morgan rand 3A4\n",
      "0.20517891522179696 y_test predictions: [0.21823384 0.16360674 0.12056739 0.12088345 0.1048593 ], 14\n",
      "     standard deviations: [2.77555756e-17 0.00000000e+00 0.00000000e+00 0.00000000e+00], 14\n",
      "0.16922235477497768 y_test predictions: [0.16759298 0.0354481  0.19902931 0.06941917 0.02125379], 14\n",
      "     standard deviations: [0. 0. 0. 0.], 14\n",
      "0.18627052410791411 y_test predictions: [ 0.94873027  0.13589371  0.16654685  0.07753215 -0.00278224], 14\n",
      "     standard deviations: [0.00390948 0.00390397 0.00401858 0.00018805], 14\n",
      "0.12532086067828963 y_test predictions: [0.33603899 0.10465765 0.14363572 0.09620703 0.07729988], 14\n",
      "     standard deviations: [0.05014722 0.01651611 0.03047523 0.00668846], 14\n",
      "0.12461641526820169 y_test predictions: [0.10732408 0.05370691 0.14169184 0.11403712 0.0233337 ], 14\n",
      "     standard deviations: [0.0493665  0.05559492 0.0445014  0.02275014], 14\n",
      "best was ANN with rmsd 0.12461641526820169\n",
      "\n",
      "\n",
      "morgan rand RLM\n",
      "0.25148738300334833 y_test predictions: [0.30065249 0.21188349 0.31241521 0.21238595 0.31505809], 356\n",
      "     standard deviations: [0. 0. 0. 0.], 356\n",
      "0.2569876569855946 y_test predictions: [0.268915 0.268915 0.268915 0.268915 0.268915], 356\n",
      "     standard deviations: [0. 0. 0. 0.], 356\n",
      "0.3248811712939371 y_test predictions: [0.39485145 0.16837996 0.4135318  0.02594391 0.34427717], 356\n",
      "     standard deviations: [2.13813046e-16 4.45754052e-02 1.14073834e-16 6.85107087e-03], 356\n",
      "0.23538231733186515 y_test predictions: [0.32601417 0.22811507 0.43503571 0.08565192 0.2618976 ], 356\n",
      "     standard deviations: [0.00996675 0.0095162  0.010723   0.00604281], 356\n",
      "0.2596204912037203 y_test predictions: [0.34986234 0.13305422 0.25222156 0.18841679 0.30767631], 356\n",
      "     standard deviations: [0.06417898 0.08706895 0.05280585 0.03217923], 356\n",
      "best was RF with rmsd 0.23538231733186515\n",
      "\n",
      "\n",
      "morgan rand HLC\n",
      "0.2908655614905891 y_test predictions: [0.81764469 0.8492001  0.3413484  0.57005122 0.95773423], 38\n",
      "     standard deviations: [0. 0. 0. 0.], 38\n",
      "0.31698247941640323 y_test predictions: [0.77503386 0.77503386 0.77503386 0.77503386 0.77503386], 38\n",
      "     standard deviations: [1.11022302e-16 0.00000000e+00 1.11022302e-16 0.00000000e+00], 38\n",
      "0.3390119412072462 y_test predictions: [ 1.26675029  0.77075754 -0.4714025   0.15133517  1.03642749], 38\n",
      "     standard deviations: [4.00139588e-02 1.25729622e-03 5.34292895e-16 3.67428829e-16], 38\n",
      "0.26514636208740994 y_test predictions: [0.63487674 0.82037638 0.71595357 0.63536423 0.88546548], 38\n",
      "     standard deviations: [0.01665015 0.01302316 0.01611288 0.01347938], 38\n",
      "0.48910891806868995 y_test predictions: [0.31511815 0.27543507 0.1225684  0.10591607 0.40476394], 38\n",
      "     standard deviations: [0.36142857 0.32083805 0.19484602 0.2288162 ], 38\n",
      "best was RF with rmsd 0.26514636208740994\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'tuple' object does not support item assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 11\u001b[0m\n\u001b[0;32m      9\u001b[0m rmsds[_type][splitter] \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m     10\u001b[0m stds[_type][splitter] \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m---> 11\u001b[0m best_models[_type][splitter] \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m isozyme \u001b[38;5;129;01min\u001b[39;00m isozymes:\n\u001b[0;32m     13\u001b[0m     y_predicted[_type][splitter][isozyme] \u001b[38;5;241m=\u001b[39m {}\n",
      "\u001b[1;31mTypeError\u001b[0m: 'tuple' object does not support item assignment"
     ]
    }
   ],
   "source": [
    "# test models with the best hyperparams\n",
    "for _type in feature_types:\n",
    "    y_predicted[_type] = {}\n",
    "    rmsds[_type] = {}\n",
    "    stds[_type] = {}\n",
    "    best_models[_type] = {}\n",
    "    for splitter in splitters:\n",
    "        y_predicted[_type][splitter] = {}\n",
    "        rmsds[_type][splitter] = {}\n",
    "        stds[_type][splitter] = {}\n",
    "        best_models[_type][splitter] = {}\n",
    "        for isozyme in isozymes:\n",
    "            y_predicted[_type][splitter][isozyme] = {}\n",
    "            rmsds[_type][splitter][isozyme] = {}\n",
    "            stds[_type][splitter][isozyme] = {}\n",
    "            group_rmsds = {}\n",
    "            print(_type, splitter, isozyme)\n",
    "            for model_id in model_identifiers:\n",
    "                hyperparams = best_model_hyperparams[_type][splitter][isozyme][model_id]\n",
    "                if _type == \"morgan\":\n",
    "                    X_train = fingerprints[\"morgan\"][splitter][isozyme][\"train\"]\n",
    "                    X_test = fingerprints[\"morgan\"][splitter][isozyme][\"test\"]\n",
    "                else:\n",
    "                    X_train = mol_features[splitter][isozyme][\"train\"]\n",
    "                    X_test = mol_features[splitter][isozyme][\"test\"]\n",
    "                y_train = np.array(halflives[_type][splitter][isozyme][\"train\"])\n",
    "                y_test = np.array(halflives[_type][splitter][isozyme][\"test\"])\n",
    "\n",
    "                if model_id == 'linear':\n",
    "                    alpha = hyperparams[\"alpha\"]\n",
    "                    l1_ratio = hyperparams[\"l1_ratio\"]\n",
    "                    reg = ElasticNet(alpha=alpha, l1_ratio=l1_ratio, fit_intercept=True)\n",
    "\n",
    "                if model_id == 'KRR':\n",
    "                    alpha = hyperparams[\"alpha\"]\n",
    "                    gamma = hyperparams[\"gamma\"]\n",
    "                    kernel = hyperparams[\"kernel\"]\n",
    "                    reg = KernelRidge(alpha=alpha, gamma=gamma, kernel=kernel)\n",
    "\n",
    "                if model_id == 'GB':\n",
    "                    n_estimators = hyperparams[\"n_estimators\"]\n",
    "                    learning_rate = hyperparams[\"learning_rate\"]\n",
    "                    max_depth = hyperparams[\"max_depth\"]\n",
    "                    reg = GradientBoostingRegressor(n_estimators=n_estimators, learning_rate=learning_rate, max_depth=max_depth)\n",
    "\n",
    "                if model_id == 'RF':\n",
    "                    n_estimators = hyperparams[\"n_estimators\"]\n",
    "                    max_features = hyperparams[\"max_features\"]\n",
    "                    max_depth = hyperparams[\"max_depth\"]\n",
    "                    reg = RandomForestRegressor(n_estimators=n_estimators, max_features=max_features, max_depth=max_depth)\n",
    "\n",
    "                if model_id == 'ANN':\n",
    "                    learning_rate_init = hyperparams[\"learning_rate_init\"]\n",
    "                    hidden_layer_sizes = hyperparams[\"hidden_layer_sizes\"]\n",
    "                    reg = MLPRegressor(learning_rate_init=learning_rate_init, hidden_layer_sizes=hidden_layer_sizes)\n",
    "\n",
    "                # create an instance of HyperparamTuner without specifying any model_identifier\n",
    "                tuner = HyperparamTuner(\"foo\", X_train, y_train, X_test, y_test)\n",
    "                # and use the train_test_return function with return_predictions to get the rmsd values\n",
    "                # average over multiple runs of the same model\n",
    "                runs_rmsds = []\n",
    "                runs_y_test_predictions = []\n",
    "                runs_stds = []\n",
    "                for i in range(10):\n",
    "                    rmsd, y_test_predictions, std = tuner.train_test_return(\"foo\", reg, return_predictions=True)\n",
    "                    runs_rmsds.append(rmsd)\n",
    "                    runs_y_test_predictions.append(y_test_predictions)\n",
    "                    runs_stds.append(std)\n",
    "                mean_rmsd = np.mean(runs_rmsds, axis=0)\n",
    "                mean_y_test_predictions = np.mean(runs_y_test_predictions, axis=0)\n",
    "                mean_stds = np.mean(runs_stds, axis=0)\n",
    "                group_rmsds[mean_rmsd] = model_id\n",
    "                rmsds[_type][model_id] = mean_rmsd\n",
    "                y_predicted[_type][model_id] = mean_y_test_predictions\n",
    "                stds[_type][model_id] = mean_stds\n",
    "                print(mean_rmsd, f\"y_test predictions: {y_test_predictions[:5]}, {len(y_test_predictions)}\")\n",
    "                print(f\"     standard deviations: {mean_stds[:4]}, {len(mean_stds)}\")\n",
    "\n",
    "            # find best model for each dataset and its rmsd\n",
    "            min_rmsd = min(group_rmsds.keys())\n",
    "            best_model = group_rmsds[min_rmsd]\n",
    "            best_models[_type] = (best_model, min_rmsd)\n",
    "            print(f\"best was {best_model} with rmsd {min_rmsd}\")\n",
    "\n",
    "            print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eae5ac8-d3ac-4f7b-af60-1af72a89c51c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for _type in feature_types:\n",
    "    tanimoto_sims[_type] = {}\n",
    "    for splitter in splitters:\n",
    "        print(splitter)\n",
    "        tanimoto_sims[_type][splitter] = {}\n",
    "        for isozyme in isozymes:\n",
    "            tanimoto_similarities = tanimoto(fingerprints[_type][splitter][isozyme][\"test\"], fingerprints[_type][splitter][isozyme][\"train\"])\n",
    "            tanimoto_sims[_type][splitter][isozyme] = tanimoto_similarities\n",
    "            median = np.median(tanimoto_similarities)\n",
    "            mean = np.mean(tanimoto_similarities)\n",
    "            print(f\"length: {len(tanimoto_similarities)}, median: {median}, arithmetic mean: {mean}, \",\n",
    "                  tanimoto_sims[_type][splitter][isozyme][:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f2daec-2db2-4747-b3cf-c0294a2846a2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a 20x3 grid of subplots\n",
    "fig, axs = plt.subplots(6, 3, figsize=(20, 30))\n",
    "\n",
    "plot_counter = 0\n",
    "# Loop through each subplot and plot different data\n",
    "for _type in feature_types:\n",
    "    for splitter in splitters:\n",
    "        for isozyme in isozymes:\n",
    "            model_id = best_models[_type][splitter][isozyme][0]\n",
    "            plot_x = tanimoto_sims[_type][splitter][isozyme]\n",
    "            plot_y = y_predicted[_type][splitter][isozyme][model_id]\n",
    "\n",
    "            # Get the current axis based on the plot counter\n",
    "            ax = axs[plot_counter // 3, plot_counter % 3]\n",
    "\n",
    "            # Plot the data and customize the subplot\n",
    "            ax.scatter(plot_x, plot_y)\n",
    "            ax.set_title(f'{_type}, {splitter}, {isozyme}, {model_id}')\n",
    "            ax.set(xlabel='tanimoto similarity', ylabel='prediction error')\n",
    "\n",
    "            plot_counter += 1\n",
    "\n",
    "plt.tight_layout()  # Ensure the subplots are properly laid out\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc21afce-f634-490f-8c7b-cebe1fa43371",
   "metadata": {},
   "outputs": [],
   "source": [
    "_type = \"morgan\"\n",
    "subplot_titles = []\n",
    "# generate plot titles\n",
    "for splitter in splitters:\n",
    "    for isozyme in isozymes:\n",
    "        model_id = best_models[_type][splitter][isozyme][0]\n",
    "        title = f'{_type}, {splitter}, {isozyme}, {model_id}'\n",
    "        subplot_titles.append(title)\n",
    "\n",
    "# Create a 20x3 grid of subplots\n",
    "fig = sp.make_subplots(rows=3, cols=3, subplot_titles=subplot_titles)\n",
    "\n",
    "plot_counter = 0\n",
    "# Loop through each subplot and plot different data\n",
    "\n",
    "for splitter in splitters:\n",
    "    for isozyme in isozymes:\n",
    "        model_id = best_models[_type][splitter][isozyme][0]\n",
    "        plot_x = halflives[_type][splitter][isozyme][\"test\"]\n",
    "        plot_y = y_predicted[_type][splitter][isozyme][model_id]\n",
    "        std = stds[_type][splitter][isozyme][model_id]\n",
    "\n",
    "        # Plot the data\n",
    "        scatter_trace = go.Scatter(\n",
    "            x=plot_x,\n",
    "            y=plot_y,\n",
    "            mode='markers',\n",
    "            error_y=dict(type='data', array=std, visible=True),\n",
    "            name=f'{_type}, {splitter}, {isozyme}, {model_id}'\n",
    "        )\n",
    "\n",
    "        # Add the diagonal line\n",
    "        diagonal_trace = go.Scatter(\n",
    "            x=plot_x,\n",
    "            y=plot_x,\n",
    "            mode='lines',\n",
    "            line=dict(color='orange', dash='dash'),\n",
    "            showlegend=False\n",
    "        )\n",
    "\n",
    "        # Add the traces to the subplot\n",
    "        fig.add_trace(scatter_trace, row=plot_counter // 3 + 1, col=plot_counter % 3 + 1)\n",
    "        fig.add_trace(diagonal_trace, row=plot_counter // 3 + 1, col=plot_counter % 3 + 1)\n",
    "\n",
    "        # Customize the subplot\n",
    "        fig.update_xaxes(title_text='real natural log half-life', row=plot_counter // 3 + 1, col=plot_counter % 3 + 1)\n",
    "        fig.update_yaxes(title_text='predicted natural log half-life', row=plot_counter // 3 + 1, col=plot_counter % 3 + 1)\n",
    "\n",
    "        plot_counter += 1\n",
    "\n",
    "# Update layout\n",
    "fig.update_layout(height=1500, title_text=\"Subplots with Plotly\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b1172b-05fa-42ba-9e71-b7ab41e9d7a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "_type = \"jazzy\"\n",
    "subplot_titles = []\n",
    "# generate plot titles\n",
    "for splitter in splitters:\n",
    "    for isozyme in isozymes:\n",
    "        model_id = best_models[_type][splitter][isozyme][0]\n",
    "        title = f'{_type}, {splitter}, {isozyme}, {model_id}'\n",
    "        subplot_titles.append(title)\n",
    "\n",
    "# Create a 20x3 grid of subplots\n",
    "fig = sp.make_subplots(rows=3, cols=3, subplot_titles=subplot_titles)\n",
    "\n",
    "plot_counter = 0\n",
    "# Loop through each subplot and plot different data\n",
    "\n",
    "for splitter in splitters:\n",
    "    for isozyme in isozymes:\n",
    "        model_id = best_models[_type][splitter][isozyme][0]\n",
    "        plot_x = halflives[_type][splitter][isozyme][\"test\"]\n",
    "        plot_y = y_predicted[_type][splitter][isozyme][model_id]\n",
    "        std = stds[_type][splitter][isozyme][model_id]\n",
    "\n",
    "        # Plot the data\n",
    "        scatter_trace = go.Scatter(\n",
    "            x=plot_x,\n",
    "            y=plot_y,\n",
    "            mode='markers',\n",
    "            error_y=dict(type='data', array=std, visible=True),\n",
    "            name=f'{_type}, {splitter}, {isozyme}, {model_id}'\n",
    "        )\n",
    "\n",
    "        # Add the diagonal line\n",
    "        diagonal_trace = go.Scatter(\n",
    "            x=plot_x,\n",
    "            y=plot_x,\n",
    "            mode='lines',\n",
    "            line=dict(color='orange', dash='dash'),\n",
    "            showlegend=False\n",
    "        )\n",
    "\n",
    "        # Add the traces to the subplot\n",
    "        fig.add_trace(scatter_trace, row=plot_counter // 3 + 1, col=plot_counter % 3 + 1)\n",
    "        fig.add_trace(diagonal_trace, row=plot_counter // 3 + 1, col=plot_counter % 3 + 1)\n",
    "\n",
    "        # Customize the subplot\n",
    "        fig.update_xaxes(title_text='real natural log half-life', row=plot_counter // 3 + 1, col=plot_counter % 3 + 1)\n",
    "        fig.update_yaxes(title_text='predicted natural log half-life', row=plot_counter // 3 + 1, col=plot_counter % 3 + 1)\n",
    "\n",
    "        plot_counter += 1\n",
    "\n",
    "# Update layout\n",
    "fig.update_layout(height=1500, title_text=\"Subplots with Plotly\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58693735-0edd-4468-aa6b-45fbfefa9a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "for _type in feature_types:\n",
    "    bar_width = 0.25\n",
    "\n",
    "    r1 = np.arange(len(splitters))\n",
    "    r2 = [x + bar_width for x in r1]\n",
    "    r3 = [x + bar_width for x in r2]\n",
    "\n",
    "    grouped_rmsds = {}\n",
    "    for splitter in splitters:\n",
    "        grouped_rmsds[splitter] = []\n",
    "        for isozyme in isozymes:\n",
    "            grouped_rmsds[splitter].append(best_models[_type][splitter][isozyme][1])\n",
    "\n",
    "    plt.bar(r1, grouped_rmsds[\"rand\"], width=bar_width, label='Bar 1')\n",
    "    plt.bar(r2, grouped_rmsds[\"scaff\"], width=bar_width, label='Bar 2')\n",
    "    plt.bar(r3, grouped_rmsds[\"time\"], width=bar_width, label='Bar 3')\n",
    "\n",
    "    plt.xlabel('splitters')\n",
    "    plt.ylabel('rmsd')\n",
    "    plt.title(f'{_type} root mean square deviations')\n",
    "    plt.xticks([r + bar_width for r in range(len(splitters))], [\"random\", \"scaffold\", \"publication date\"])\n",
    "    plt.legend(isozymes)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b93f0f59-84b4-4fee-a5c1-b1b55f60b661",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
