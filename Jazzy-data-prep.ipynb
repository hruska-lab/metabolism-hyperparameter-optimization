{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e1552ad-a611-413a-b0d2-ccd245e4d499",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tdc.single_pred import ADME\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from jazzy.api import molecular_vector_from_smiles as mol_vect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d425f5e3-a2ec-47dd-a882-8bc65db5aa1e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tdc_benchmarks = [\"obach\", \"microsome\", \"hepatocyte\"]\n",
    "tdc_datasets = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a7ddfc9e-ef2b-4de3-bad9-9a268d9a1052",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found local copy...\n",
      "Loading...\n",
      "Done!\n",
      "Found local copy...\n",
      "Loading...\n",
      "Done!\n",
      "Found local copy...\n",
      "Loading...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# download/load benchmark datasets from TDC-ADME\n",
    "obach = ADME(name='Half_Life_Obach')\n",
    "obach_split = obach.get_split()\n",
    "tdc_datasets[\"obach\"] = obach_split\n",
    "microsome = ADME(name='Clearance_Microsome_AZ')\n",
    "microsome_split = microsome.get_split()\n",
    "tdc_datasets[\"microsome\"] = microsome_split\n",
    "hepatocyte = ADME(name='Clearance_Hepatocyte_AZ')\n",
    "hepatocyte_split = hepatocyte.get_split()\n",
    "tdc_datasets[\"hepatocyte\"] = hepatocyte_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "94480987-4d95-4c30-8874-689c378dfe02",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(534,) (534,) (133,) (133,)\n",
      "both obach_train.csv and obach_test.csv already exist in project_resources/jazzy_splits/TDC\n",
      "(882,) (882,) (220,) (220,)\n",
      "both microsome_train.csv and microsome_test.csv already exist in project_resources/jazzy_splits/TDC\n",
      "(970,) (970,) (243,) (243,)\n",
      "both hepatocyte_train.csv and hepatocyte_test.csv already exist in project_resources/jazzy_splits/TDC\n"
     ]
    }
   ],
   "source": [
    "# create csv files with Jazzy features if not already created\n",
    "for benchmark in tdc_benchmarks:\n",
    "    #get the smiles and half-lives from datasets\n",
    "    train_smiles = np.array(list(tdc_datasets[benchmark][\"train\"][\"Drug\"]) + list(tdc_datasets[benchmark][\"valid\"][\"Drug\"]))\n",
    "    train_halflives = np.array(list(tdc_datasets[benchmark][\"train\"][\"Y\"]) + list(tdc_datasets[benchmark][\"valid\"][\"Y\"]))\n",
    "    test_smiles = np.array(list(tdc_datasets[benchmark][\"test\"][\"Drug\"]))\n",
    "    test_halflives = np.array(list(tdc_datasets[benchmark][\"test\"][\"Y\"]))\n",
    "\n",
    "    # scale train half-lives\n",
    "    reshaped_train_halflife = np.array(train_halflives).reshape(-1, 1)\n",
    "    scaler = MinMaxScaler().fit(reshaped_train_halflife)\n",
    "    train_halflife_scaled = scaler.transform(reshaped_train_halflife)\n",
    "    train_halflives_scaled = np.array([val[0] for val in train_halflife_scaled])\n",
    "\n",
    "    # scale test half-lives\n",
    "    reshaped_test_halflife = np.array(test_halflives).reshape(-1, 1)\n",
    "    scaler = MinMaxScaler().fit(reshaped_test_halflife)\n",
    "    test_halflife_scaled = scaler.transform(reshaped_test_halflife)\n",
    "    test_halflives_scaled = np.array([val[0] for val in test_halflife_scaled])\n",
    "    \n",
    "    print(train_smiles.shape, train_halflives_scaled.shape, test_smiles.shape, test_halflives_scaled.shape)\n",
    "\n",
    "    \n",
    "    try:\n",
    "        df = pd.read_csv(f\"project_resources/jazzy_splits/{benchmark}_train.csv\")\n",
    "        df = pd.read_csv(f\"project_resources/jazzy_splits/{benchmark}_test.csv\")\n",
    "        print(f\"both {benchmark}_train.csv and {benchmark}_test.csv already exist in project_resources/jazzy_splits/TDC\")\n",
    "    \n",
    "    except FileNotFoundError:\n",
    "        # generate Jazzy features and save to csv files\n",
    "        train_jazzy_fps = []\n",
    "        train_jazzy_thalfs = []\n",
    "        test_jazzy_fps = []\n",
    "        test_jazzy_thalfs = []\n",
    "\n",
    "        # train split\n",
    "        for smi, thalf in zip(train_smiles, train_halflives_scaled):\n",
    "            try:\n",
    "                jazzy_fp = mol_vect(smi)\n",
    "            except:\n",
    "                jazzy_fp = None\n",
    "            if jazzy_fp and not np.isnan(np.array(list(jazzy_fp.values()))).any():\n",
    "                jazzy_fp_list = np.array([fp for fp in jazzy_fp.values()])\n",
    "                train_jazzy_fps.append(jazzy_fp_list)\n",
    "                train_jazzy_thalfs.append(thalf)\n",
    "\n",
    "        # test split\n",
    "        for smi, thalf in zip(test_smiles, test_halflives_scaled):\n",
    "            try:\n",
    "                jazzy_fp = mol_vect(smi)\n",
    "            except:\n",
    "                jazzy_fp = None\n",
    "            if jazzy_fp and not np.isnan(np.array(list(jazzy_fp.values()))).any():\n",
    "                jazzy_fp_list = np.array([fp for fp in jazzy_fp.values()])\n",
    "                test_jazzy_fps.append(jazzy_fp_list)\n",
    "                test_jazzy_thalfs.append(thalf)\n",
    "\n",
    "        print(np.array(train_jazzy_fps).shape, np.array(train_jazzy_thalfs).shape, np.array(test_jazzy_fps).shape, np.array(test_jazzy_thalfs).shape)\n",
    "\n",
    "        train_jazzy_csv = f\"project_resources/jazzy_splits/{benchmark}_train.csv\"\n",
    "        df = pd.DataFrame(train_jazzy_fps, columns=['sdc', 'sdx', 'sa', 'dga', 'dgp', 'dgtot'])\n",
    "        df.insert(0, \"half-life\", train_jazzy_thalfs)\n",
    "        df.to_csv(train_jazzy_csv, index=False)\n",
    "        print(f\"{train_jazzy_csv} was successfully created\")\n",
    "\n",
    "        test_jazzy_csv = f\"project_resources/jazzy_splits/{benchmark}_test.csv\"\n",
    "        df = pd.DataFrame(test_jazzy_fps, columns=['sdc', 'sdx', 'sa', 'dga', 'dgp', 'dgtot'])\n",
    "        df.insert(0, \"half-life\", test_jazzy_thalfs)\n",
    "        df.to_csv(test_jazzy_csv, index=False)\n",
    "        print(f\"{test_jazzy_csv} was successfully created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b246649b-55e6-4699-8b22-be1d5052df30",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
