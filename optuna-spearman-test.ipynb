{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "90f229a1-c4f0-42d9-bb7b-4d76a30dc391",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import csv\n",
    "import sys\n",
    "import time\n",
    "import joblib\n",
    "import py3Dmol\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "import numpy as np\n",
    "from tdc.single_pred import ADME\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from scipy.stats import spearmanr\n",
    "import optuna\n",
    "from project_resources.import_utils import NotebookFinder\n",
    "sys.meta_path.append(NotebookFinder())\n",
    "from project_resources.cytochrome_P450 import load_ml_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a876a2d-9cb4-4866-83dd-3113a10acbae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class HyperparamTuner():\n",
    "    def __init__(self, log_csv_path, model_identifier, X_train, y_train, X_val, y_val):\n",
    "        self.log_csv_path = log_csv_path\n",
    "        self.model_identifier = model_identifier\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "        self.X_val = X_val\n",
    "        self.y_val = y_val\n",
    "\n",
    "    def sample_params(self, trial: optuna.Trial, model_identifier):\n",
    "        if model_identifier == 'linear':\n",
    "            alpha = trial.suggest_float('alpha', 0.005, 0.1)\n",
    "            l1_ratio = trial.suggest_float('l1_ratio', 0, 0.05)\n",
    "            return {\n",
    "                \"alpha\": alpha,\n",
    "                \"l1_ratio\": l1_ratio\n",
    "            }, ElasticNet(alpha=alpha, l1_ratio=l1_ratio)\n",
    "\n",
    "        if model_identifier == 'KRR':\n",
    "            alpha = trial.suggest_float(\"alpha\", 0.3, 1)\n",
    "            gamma = trial.suggest_float(\"gamma\", 0.1, 0.3)\n",
    "            kernel = trial.suggest_categorical(\"kernel\", [\"laplacian\", \"rbf\"])\n",
    "            return {\n",
    "                \"alpha\": alpha,\n",
    "                \"gamma\": gamma,\n",
    "                \"kernel\": kernel\n",
    "            }, KernelRidge(alpha=alpha, gamma=gamma, kernel=kernel)\n",
    "\n",
    "        if model_identifier == 'GB':\n",
    "            n_estimators = trial.suggest_categorical(\"n_estimators\", [5, 10, 20, 50])\n",
    "            learning_rate = trial.suggest_float(\"learning_rate\", 0.05, 0.175)\n",
    "            max_depth = trial.suggest_categorical(\"max_depth\", [1, 2, 3])\n",
    "            return {\n",
    "                \"n_estimators\": n_estimators,\n",
    "                \"learning_rate\": learning_rate,\n",
    "                \"max_depth\": max_depth\n",
    "            }, GradientBoostingRegressor(n_estimators=n_estimators, learning_rate=learning_rate, max_depth=max_depth)\n",
    "\n",
    "        if model_identifier == 'RF':\n",
    "            n_estimators = trial.suggest_categorical(\"n_estimators\", [500, 750, 1000])\n",
    "            max_features = trial.suggest_categorical(\"max_features\", [\"sqrt\", \"log2\"])\n",
    "            max_depth = trial.suggest_categorical(\"max_depth\", [None, 2, 5, 10, 20])\n",
    "            return {\n",
    "                \"n_estimators\": n_estimators,\n",
    "                \"max_features\": max_features,\n",
    "                \"max_depth\": max_depth\n",
    "            }, RandomForestRegressor(n_estimators=n_estimators, max_features=max_features, max_depth=max_depth)\n",
    "\n",
    "        if model_identifier == 'ANN':\n",
    "            learning_rate_init = trial.suggest_float(\"learning_rate_init\", 0.05, 0.15)\n",
    "            hidden_layer_sizes = trial.suggest_categorical(\"hidden_layer_sizes\",\n",
    "                                                           [[3]*3, [5]*3, [3]*5, [5]*5, [10]*3])\n",
    "            return {\n",
    "            \"learning_rate_init\": learning_rate_init,\n",
    "            \"hidden_layer_sizes\": hidden_layer_sizes\n",
    "            }, MLPRegressor(solver=\"lbfgs\", learning_rate_init=learning_rate_init, hidden_layer_sizes=hidden_layer_sizes)\n",
    "\n",
    "    def evaluate(self, model, X_val, y_val):\n",
    "        predictions = model.predict(X_val)\n",
    "        spearman = spearmanr(y_val, predictions).statistic\n",
    "        return abs(spearman), predictions\n",
    "\n",
    "    def train_val_return(self, trial, parameters, model, trial_number):\n",
    "        runs = 3\n",
    "        runs_results = []\n",
    "        runs_predictions = []\n",
    "        \n",
    "        # ensure that the models don't predict only one value (if they do, spearman is nan)\n",
    "        for run in range(runs):\n",
    "            # pythonic \"do-while loop\"\n",
    "            while True:\n",
    "                model.fit(self.X_train, self.y_train)\n",
    "                run_spearman, run_predicts = self.evaluate(model, self.X_val, self.y_val)\n",
    "                if not np.isnan(run_spearman):\n",
    "                    break\n",
    "            # Handle pruning based on the intermediate value.\n",
    "            trial.report(run_spearman, run)\n",
    "            if trial.should_prune():\n",
    "                raise optuna.TrialPruned()\n",
    "            runs_results.append(run_spearman)\n",
    "            runs_predictions.append(run_predicts)\n",
    "\n",
    "        # calculate the standard deviation of predictions\n",
    "        runs_predictions = np.array(runs_predictions)\n",
    "        std = np.std(runs_predictions, axis=0)\n",
    "        \n",
    "        average_result = np.mean(runs_results)\n",
    "        average_predictions = np.mean(runs_predictions, axis=0)\n",
    "        \n",
    "        # write the result and hyperparameters of a run to csv file\n",
    "        optuna_trial_logging(self.log_csv_path, trial_number, parameters, average_result, average_predictions, std)\n",
    "\n",
    "        return average_result\n",
    "\n",
    "    def objective(self, trial=None):\n",
    "        parameters, model = self.sample_params(trial, self.model_identifier)\n",
    "        return self.train_val_return(trial, parameters, model, trial.number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e7341e50-f7cb-4c1c-908c-e1f00558e98c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def _evaluate(model, X_val, y_val):\n",
    "    predictions = model.predict(X_val)\n",
    "    spearman = spearmanr(y_val, predictions).statistic\n",
    "    return abs(spearman), predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "31274d1f-4356-4313-b2cc-b2383fd28c80",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found local copy...\n",
      "Loading...\n",
      "Done!\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 667/667 [00:00<00:00, 795.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running: [10]*3\n",
      "Average: 0.52\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train, X_val, y_val, X_test, y_test = load_ml_data(\"morgan\", \"obach\")\n",
    "\n",
    "model = MLPRegressor(solver=\"lbfgs\", learning_rate_init=0.05, hidden_layer_sizes=[10]*3)\n",
    "print(f\"Running: [10]*3\")\n",
    "\n",
    "all_times = []\n",
    "for i in range(10):\n",
    "    t_start = time.time()\n",
    "    # ensure that the models don't predict only one value (if they do, spearman is nan)\n",
    "    for run in range(runs):\n",
    "        num_iter = 0\n",
    "        # pythonic \"do-while loop\"\n",
    "        while True:\n",
    "            num_iter += 1\n",
    "            model.fit(X_train, y_train)\n",
    "            run_spearman, run_predicts = _evaluate(model, X_val, y_val)\n",
    "            #print(\"spearman:\", run_spearman)\n",
    "            if not np.isnan(run_spearman):\n",
    "                #print(\"spearman:\", run_spearman)\n",
    "                break\n",
    "    t_end = time.time()\n",
    "    total_time = round(t_end-t_start, 2)\n",
    "    all_times.append(total_time)\n",
    "print(f\"Average: {round(np.average(all_times), 2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "6ca25f4e-30ca-476a-9997-bcacbffb130d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# [3]*3 -> 1.05\n",
    "# [3]*5 -> 1.75\n",
    "# [5]*3 -> 0.6\n",
    "# [5]*5 -> 0.75\n",
    "# [10]*3 -> 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7aae344-8791-45ad-8cb4-740f69b7cf0e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
